3.3節で述べたランダムフォレストを用いて、実際に欠陥予測モデルを構築し評価する。

\paragraph{ランダムフォレストの実装}
本研究では、ランダムフォレストを用いて欠陥混入予測モデルを構築する。
ランダムフォレストは、複数の決定木を構築し、それらの予測結果を集約することで高い予測精度と汎化性能を実現するアンサンブル学習手法である。

図\ref{fig:decision_tree}に決定木の構造を示す。
決定木は、各ノードにおいて特徴量の閾値に基づいてデータを分割し、葉ノードで最終的な予測クラスを出力する。
しかし、単一の決定木は訓練データに過適合しやすく、汎化性能が低下する傾向がある。

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.7\linewidth]{figures/decision_tree.pdf}
  \caption{決定木の構造}
  \label{fig:decision_tree}
\end{figure}

ランダムフォレストでは、この問題を解決するためにブートストラップサンプリングを用いる。
図\ref{fig:bootstrap_sampling}に示すように、元の訓練データセットから復元抽出により複数の異なるサンプルを生成し、各サンプルに対して独立に決定木を学習する。
この手法により、各決定木は異なるデータの特性を学習し、多様性のあるモデル集団を構築することができる。

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.85\linewidth]{figures/bootstrap_sampling.pdf}
  \caption{ブートストラップサンプリングによる訓練データの生成}
  \label{fig:bootstrap_sampling}
\end{figure}

図\ref{fig:random_forest}に、ランダムフォレストによる分類の流れを示す。
各決定木は独立に予測を行い、分類問題では多数決により最終的な予測クラスが決定される。
また、各分岐点では全特徴量ではなくランダムに選択された特徴量の部分集合のみが使用されるため、決定木間の相関がさらに低減され、モデルの汎化性能が向上する。

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.95\linewidth]{figures/random_forest_classification.pdf}
  \caption{ランダムフォレストによる分類プロセス}
  \label{fig:random_forest}
\end{figure}

\paragraph{モデルの段階的評価}
提案手法の各要素がどの程度予測性能に寄与するかを明らかにするため、3段階の比較評価を行う。

ステップ1: はじめに、変更メトリクスを追加する前のモデルを構築する。このモデルは、BugHunter Datasetに元々含まれているコードメトリクスのみを特徴量として使用する。このモデルをベースラインとし、後続のモデルとの比較基準とする。

ステップ2: ベースラインモデルに対して、メソッド単位の変更メトリクスを追加したモデルを構築する。これにより、メソッド単位の時系列変化を考慮することの効果を評価する。

ステップ3: ステップ2のモデルに対して、さらにコミット単位の変更メトリクスを追加したモデルを構築する。これにより、ミクロ的視点とマクロ的視点を統合することの効果を評価する。

\paragraph{モデルの訓練と評価手順}
各モデルに対して、以下の手順で訓練と評価を行う。

\textbf{データ分割}: 各プロジェクトのデータセットを訓練データとテストデータに分割する。訓練データはモデルの学習に使用し、テストデータは最終的な性能評価に使用する。

\textbf{10分割交差検証}: 訓練データに対して10分割交差検証を実施し、モデルの性能の誤差を測定する。データセットを10個のサブセットに分割し、そのうち9個を訓練データ、1個を検証データとして使用する。この過程を10回繰り返し、各サブセットが1度だけ検証データとして使用されるようにする。各フェーズでF1スコア、適合率、再現率を計算し、性能のばらつきを評価する。

\textbf{最終評価}: 訓練されたモデルをテストデータに適用し、F1スコア、適合率、再現率、正解率、ROC-AUCを算出する。この値を各モデルの最終的な性能指標とする。

\textbf{統計的有意性の検証}: 提案手法（ステップ3）とベースライン（ステップ1）の予測結果に統計的に有意な差があるかを検証するため、マクネマー検定を実施する。マクネマー検定は、同じテストデータに対する2つの分類器の予測結果を比較するための統計的検定手法であり、p値が0.05未満の場合、有意な差があると判断する。

\paragraph{モデル解釈性の分析}
構築したモデルがどのような判断基準で予測を行っているかを理解するため、以下の分析を実施する。

\textbf{特徴量の寄与度の算出}: ランダムフォレストが提供するFeature Importanceを計算し、どの特徴量が予測に最も寄与しているかを明らかにする。Feature Importanceは、各特徴量が決定木の分岐においてどの程度情報利得をもたらしたかを示す指標である。この分析により、メソッド単位の変更メトリクスとコミット単位の変更メトリクスのうち、どの特徴量がバグ予測に重要であるかを定量的に評価できる。

\textbf{Partial Dependence Plot（PDP）の生成}: 各特徴量と陽性予測確率の関係を可視化するため、PDPを生成する。

モデルの解釈可能性を高めるため、特徴量重要度の分析に加えて、Partial Dependence Plot (PDP)を用いた分析を行う。
PDPは、特定の特徴量の値を変化させたときのモデルの予測値の平均的な変化を可視化する手法である。
図\ref{fig:pdp}に示すように、特徴量$x_s$に対するPartial Dependence関数は、他の特徴量の値を固定した状態で$x_s$を変化させた際の予測値の平均として計算される。

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.9\linewidth]{figures/partial_dependence_plot.pdf}
  \caption{Partial Dependence Plotの計算方法}
  \label{fig:pdp}
\end{figure}

特徴量$x_s$に対するPartial Dependence関数$\hat{f}_{x_s}$は以下のように定義される:

\begin{equation}
\hat{f}_{x_s}(x_s) = \frac{1}{n}\sum_{i=1}^{n}\hat{f}(x_s, \mathbf{x}_{\backslash s}^{(i)})
\end{equation}

ここで、$\hat{f}$は学習されたモデル、$\mathbf{x}_{\backslash s}^{(i)}$は$i$番目のサンプルにおける特徴量$x_s$以外の特徴量の値を表す。
この分析により、各特徴量の値の変化が欠陥混入確率に与える影響の方向性と大きさを定量的に把握することができる。

\textbf{決定木の可視化}: ランダムフォレストを構成する決定木の一つを可視化し、どのような分類条件でバグの有無を判断しているかを確認する。決定木の可視化により、モデルの判断基準と確信度を具体的に把握できる。