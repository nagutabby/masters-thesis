機械学習技術の進展により、欠陥予測の精度は大きく向上してきた。Menziesらは、ナイーブベイズ、決定木、ロジスティック回帰など複数の機械学習アルゴリズムを比較し、適切なアルゴリズム選択の重要性を示した\cite{menzies2007}。彼らの研究では、単純なアルゴリズムでも様々な特徴量を組み合わせることで高い欠陥予測性能が得られることが示された。

ランダムフォレストは、欠陥予測において広く用いられるアルゴリズムである。Ghotraらは、ノイズが除去されたNASAデータセットと、PROMISEを用いた比較実験により、決定木ベースの機械学習アルゴリズムが他のアルゴリズムと比較して安定した高い性能を示すことを確認した\cite{ghotra2015}。決定木を用いたアルゴリズムの利点は、過学習に強く、非線形な関係を捉えられ、特徴量の重要度を解釈できることである。

欠陥予測における重要な課題の一つは、データの不均衡である。実際のソフトウェアでは、欠陥を含むコードは全体の一部であり、陽性クラス(欠陥あり)と陰性クラス(欠陥なし)の比率が大きく偏っている。この不均衡は予測性能を低下させる要因となる。

不均衡データへの対処として、サンプリング技術が用いられる。サンプリング技術は大きく2つのアプローチに分けられる。アンダーサンプリングは、多数クラス(欠陥なし)のサンプル数を削減することでクラス間のバランスを取る手法である。この手法の長所は、学習データ数を削減するため計算コストが低く、学習時間が短縮されることである。短所は、多数クラスから重要なサンプルを削除してしまう可能性があり、多数クラスに関する情報が失われることである。一方、オーバーサンプリングは、少数クラス(欠陥あり)のサンプル数を増加させる手法である。長所は、元のデータから情報を失うことなく、少数クラスの特徴をより詳細に学習できることである。短所は、データサイズが増加するため計算コストと学習時間が増大することと、同じサンプルの複製や類似サンプルの生成により過学習のリスクが高まることである。

機械学習モデルの解釈性も重要な課題である。実務での活用には、なぜそのコミットが欠陥を含むと予測されたのかを理解できることが求められる。特徴量の重要度分析やPartial Dependence Plot\cite{friedman2001}などの手法により、モデルの判断根拠をある程度可視化できる。決定木ベースの機械学習アルゴリズムは解釈性が比較的高く、特徴量重要度を計算できる利点がある。

しかし、多くの研究では予測性能の向上に焦点が当てられ、実務での運用を考慮した研究は限定的である。特に、予測結果をどのようにレビュープロセスに組み込むか、限られたレビューリソースの下でどのコミットを優先すべきかという最適化の問題は、十分に探求されていない。