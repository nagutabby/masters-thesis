従来のソフトウェア欠陥予測手法では、ファイルやパッケージ単位での予測が主流であった。このアプローチでは、McCabeの循環的複雑度やCKメトリクス、コード行数といったコードメトリクス、あるいは過去の欠陥数や変更回数といったプロセスメトリクスを用いて、欠陥が発生しやすいモジュールを特定する。しかし、このアプローチには以下の3つの問題点がある。第一に、予測単位の粒度が大きいため、重要なファイルが特定された後も、開発者はレビューやテストの対象となる具体的な関数やコードの断片を見つけるのにかなりの時間を費やす必要がある。第二に、予測がモジュール単位で行われるため、誰がその品質保証活動を担当すべきかが明確でない。第三に、予測が開発サイクルの遅い段階で行われるため、問題が発見された時点では既に多くのコードが書かれており、修正コストが高くなる。

これらの問題に対処するため、Kameiら\cite{kamei2013}は、ファイルやパッケージではなく、コミット単位での欠陥予測を行う「Just-In-Time品質保証」というアプローチを提案した。このアプローチでは、開発者がコードをリポジトリにコミットした直後に、その変更が欠陥を誘発するリスクを予測する。これにより、開発者は記憶が新しいうちにリスクの高い変更をレビューやテストできるため、より効率的かつ効果的な品質保証活動が可能になる。変更単位での予測には、予測単位の粒度が小さいこと、変更を行った開発者への具体的な作業割り当てとして予測を表現できること、開発サイクルの早い段階で予測が行われることという3つの利点がある。

Kameiらは、コード変更から抽出した特徴量を5つのカテゴリーに分類し、合計14個の変更メトリクスを提案した。これらのメトリクスは以下の通りである。

\begin{itemize}
    \item Diffusion
    \begin{itemize}
        \item 変更の拡散範囲を測定するメトリクスであり、NS（変更されたサブシステムの数）、ND（変更されたディレクトリの数）、NF（変更されたファイルの数）、Entropy（各ファイル間の変更されたコードの分散度）が含まれる。広範囲に分散した変更は理解が複雑になり、全ての変更箇所を追跡する必要があるため、欠陥発生リスクが高いと考えられる。
    \end{itemize}
    \item Size
    \begin{itemize}
        \item 変更の規模を測定するメトリクスであり、LA（追加されたコード行数）、LD（削除されたコード行数）、LT（変更前のファイルのコード行数）が含まれる。変更が大きいほど、より多くのコードの変更や実装が必要となるため、欠陥が発生する可能性が高くなる。
    \end{itemize}
    \item Purpose
    \begin{itemize}
        \item 変更の目的を示すメトリクスであり、FIX（変更が欠陥修正であるかどうか）が含まれる。欠陥を修正する変更は、以前の実装で欠陥が混入したことを意味し、その箇所に再び欠陥が混入しやすい可能性がある。
    \end{itemize}
    \item History
    \begin{itemize}
        \item ファイルの変更履歴を測定するメトリクスであり、NDEV（変更されたファイルを変更した開発者数）、AGE（直前の変更と現在の変更の間の平均時間間隔）、NUC（変更されたファイルへのユニークな変更回数）が含まれる。過去の研究では、ファイルに対する過去の変更回数と欠陥修正回数は、ファイルのバグの多さを示す良い指標であることが示されている。
    \end{itemize}
    \item Experience
    \begin{itemize}
        \item 開発者の経験を測定するメトリクスであり、EXP（開発者の全体的な経験）、REXP（開発者の最近の経験）、SEXP（サブシステムにおける開発者の経験）が含まれる。経験が豊富な開発者ほど欠陥を導入しにくいと考えられる。
    \end{itemize}
\end{itemize}

Kameiらは、6つのOSSプロジェクトと5つの商用プロジェクトを対象とした大規模な実証研究を実施した。多重共線性に対処するため、高い相関関係にある因子を除去し、NDとREXPをモデルから除外した。また、LAとLDをLTで割って正規化し（LA/LT、LD/LT）、LTとNUCをNFで割って正規化した（LT/NF、NUC/NF）。その結果、最終的に12個のメトリクスを用いてロジスティック回帰モデルを構築した。10分割交差検証による評価の結果、OSSプロジェクトでは平均適合率37\%、平均再現率67\%、商用プロジェクトでは平均適合率32\%、平均再現率62\%を達成した。

さらに、レビュー労力削減効果を評価するため、変更された行の総数を用いて労力を計算し、総労力の20\%をレビューに使用できると仮定した。予測されたロジスティック確率に基づいて変更を優先順位付けし、労力考慮型モデル（EALR）を構築した。その結果、OSSプロジェクトでは平均28\%、商用プロジェクトでは平均43\%の欠陥を誘発する変更を、総労力の20\%で特定できることが示された。これは、Just-In-Time品質保証が最もリスクの高い変更に集中するための効果的な手法であることを示している。しかし、この手法には重要な単純化が含まれている。レビュー労力を「変更された行の総数」のみで計算しているため、変更の複雑さや影響範囲の広さが考慮されていない。実際のレビュー労力は、変更されたファイル数や変更の分散度（Entropy）といった要因にも依存すると考えられるが、Kameiらの手法ではこれらの要因が労力計算に反映されていない。

特徴量の重要性を分析した結果、OSSプロジェクトではNF、LA/LT、LT/NF、FIXが、商用プロジェクトではNF、LA/LT、LT/NF、NDEV、AGEが、欠陥リスクを増加させる最も重要な要因であることが明らかになった。ただし、これらのメトリクスにはいくつかの問題点が存在する。FIXは特定のコミットが欠陥修正であるかどうかを示すフラグであり、どのメソッドやクラスが欠陥を誘発しやすいかという具体的な情報を提供しない。AGEは商用プロジェクトでは有効だが、OSSプロジェクトではボランティアベースで開発が行われるため、開発頻度が不定期であり効果的ではない。NDEVも商用プロジェクトではチームでの共同作業が多いため有効だが、OSSプロジェクトでは1つの変更は基本的に1人の開発者が担当するため効果的ではない。NSはサブシステムの総数がプロジェクトによって異なるため、プロジェクト間での比較が困難である。Entropyは適切なモジュール分割を行った場合でも、変更が複数のファイルに分散していれば欠陥発生リスクが高いと判断されてしまう。