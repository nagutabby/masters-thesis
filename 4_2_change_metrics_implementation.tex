3.2節で定義した変更メトリクスを実際のデータセットに適用するため、以下の実装を行う。

\paragraph{メソッド単位の変更メトリクスの計算}
メソッド単位の変更メトリクスとして、コード行数の変化量、トークン数の変化量、循環的複雑度の変化量を算出する。これらは、同一メソッドの欠陥混入時あるいは欠陥修正時とその直前のコミットの値の差分から計算される。

具体的には、BugHunterデータセットに含まれる各メソッドについて、欠陥混入コミットまたは欠陥修正コミットにおける値と、その直前のコミットにおける値を取得し、以下の計算を行う。

\begin{itemize}
    \item コード行数の変化量 = 現在のコミットにおけるコード行数 - 直前のコミットにおけるコード行数
    \item トークン数の変化量 = 現在のコミットにおけるトークン数 - 直前のコミットにおけるトークン数
    \item 循環的複雑度の変化量 = 現在のコミットにおける循環的複雑度 - 直前のコミットにおける循環的複雑度
\end{itemize}

これらのメソッド単位の変更メトリクスは、メソッドがどの程度変更されたかを表現する指標となる。

\paragraph{コミット単位の変更メトリクスの計算}
コミット単位の変更メトリクスとして、変更されたファイル数、コードの追加行数、コードの削除行数、変更の広がりを生成する。これらは、BugHunterデータセットに含まれるコミット情報から以下のように計算される。

\begin{itemize}
    \item 変更されたファイル数: 現在のコミットと直前のコミットの間の変更されたファイル数
    \item コードの追加行数: 現在のコミットと直前のコミットの間のコードの追加行数
    \item コードの削除行数: 現在のコミットと直前のコミットの間のコードの削除行数
    \item 変更の広がり: $\bar{H}_i$
\end{itemize}

これらのコミット単位の変更メトリクスは、コミット全体における変更の規模や複雑度を捉える。

\paragraph{メソッドの操作タイプのラベル付与}
メソッドの操作タイプ（追加、変更、削除）は、欠陥混入リスクと密接に関係している。新たに追加されたメソッドは既存のコードとの間で予期しない相互作用を引き起こす可能性があり、既存のメソッドの変更は意図しない副作用を生む可能性がある。先行研究において、新たに追加されたコードは既存のコードと比較して欠陥密度が高い傾向があることが示されている。

各メソッドに対して、追加、変更、削除のいずれの操作が行われたかを示すラベルを付与する。これらの操作タイプは、欠陥混入コミットあるいは欠陥修正コミットと、その直前のコミットを比較することで判定される。

\begin{itemize}
    \item 追加: 直前のコミットには存在せず、そのコミットで新たに追加されたメソッド
    \item 変更: 直前のコミットとそのコミットの両方に存在し、内容が変更されたメソッド
    \item 削除: 直前のコミットには存在したが、そのコミットで削除されたメソッド
\end{itemize}

これらのラベルをOne-Hotエンコーディングを用いて数値ベクトルに変換し、カテゴリカル変数として扱う。例えば、「追加」は [1, 0, 0]、「変更」は [0, 1, 0]、「削除」は [0, 0, 1] のようにエンコードされる。

\paragraph{メソッドの識別子の処理}
メソッドの識別子を特徴量として用いる理由は、識別子に含まれる、類似性に関する特徴から欠陥混入リスク推測できるためである。メソッド名やクラス名には通常、機能を示す単語が含まれる。例えば"parse"、"serialize"、"validate"といった単語を含むメソッドは、入力検証やデータ変換に関わるため、エッジケースの考慮不足による欠陥が発生しやすい。また、パッケージ構造も重要な情報を提供する。特定のパッケージ（例えば、ネットワーク処理やデータベース接続）に属するメソッドは、外部モジュールとの相互作用に起因する欠陥が発生しやすい。

メソッドの識別子をそのまま特徴量として扱うと、メソッド間のテキストの類似性を捉えられない。例えば、`getUserName()`と`getUserAge()`は、どちらも「get」と「user」という共通要素を持ち、ユーザー情報を取得するという類似した機能を持つが、識別子全体を独立したカテゴリーとして扱うと、この類似性を認識できない。さらに、訓練データに存在しない新しいメソッド名に対しては、全く予測ができなくなる。

この問題を解決するため、メソッドの識別子をいくつかの要素に分解する。具体的には、トークン分割により、`getUserName()`は["user", "name"]に、`getUserAge()`は["user", "age"]に分解され、両者が「user」という共通要素を持つことを認識できるようになる。これにより、モデルは「userに関連するメソッド」という抽象的な特徴を学習でき、訓練データに存在しない`getUserEmail()`のような新しいメソッドに対しても、["user", "email"]というトークンから適切に予測できるようになる。このトークン分割では以下の処理を実行する。

\begin{enumerate}
    \item 正規表現を用いてメソッドの完全修飾名からパッケージ名、クラス名、メソッド名を抽出する
    \item パッケージ名を.で分割し、各部分をトークンとする
    \item クラス名を\$で分割し、各部分をキャメルケース分割する（例: "UserManager" → ["User", "Manager"]）
    \item メソッド名をスネークケース（\_や-）で分割した後、さらにキャメルケース分割する（例: "get\_user\_name" → ["get", "user", "name"]）
    \item <init>や<clinit>などの特殊なメソッド名は"constructor"というトークンに変換する
    \item 全てのトークンを小文字に変換する
    \item 高頻度で出現するトークンと指定文字数未満のトークンを除外する
\end{enumerate}

表\ref{tab:tokenization_example}に、実際のメソッドの完全修飾名に対するトークン分割の例を示す。

\begin{table}[ht]
\centering
\caption{メソッド識別子のトークン分割の例}
\label{tab:tokenization_example}
\begin{tabular}{|l|p{8cm}|}
\hline
処理ステップ & 結果 \\
\hline
元のメソッドの完全修飾名 & 
\begin{tabular}{l}
com.example.user.UserManager\\.getUserName()Ljava/lang/String; \\
\end{tabular} \\
\hline
パッケージ分割 & ["com", "example", "user"] \\
\hline
クラス名のキャメルケース分割 & ["User", "Manager"] \\
\hline
メソッド名のキャメルケース分割 & ["get", "User", "Name"] \\
\hline
小文字化 & ["com", "example", "user", "user", "manager", "get", "user", "name"] \\
\hline
高頻度で出現するトークンの除去 & ["example", "user", "manager", "user", "name"] \\
\hline
重複するトークンの除去 & ["example", "user", "manager", "name"] \\
\hline
\end{tabular}
\end{table}

この例では、"com"と"get"が高頻度で出現するトークンとして除外され、"user"は複数回出現するが意味的に重要な単語として保持される。最終的に["example", "user", "manager", "name"]という、メソッドの機能を表す有用なトークンが抽出される。

表\ref{tab:tokenization_comparison}に、異なる種類のメソッドに対するトークン分割の比較例を示す。

\begin{table}[ht]
\centering
\caption{異なるメソッドタイプのトークン分割比較}
\label{tab:tokenization_comparison}
\begin{tabular}{|l|p{5cm}|p{5cm}|}
\hline
メソッドタイプ & 元のメソッド名 & 抽出されるトークン \\
\hline
データ検証 & {validateEmail()} & ["validate", "email"] \\
\hline
JSON解析 & {parseJsonData()} & ["parse", "json", "data"] \\
\hline
データベース接続 & {connectToDatabase()} & ["connect", "database"] \\
\hline
HTTP通信 & {sendHttpRequest()} & ["send", "http", "request"] \\
\hline
コンストラクター & {<init>()} & ["constructor"] \\
\hline
\end{tabular}
\end{table}

頻繁に出現するトークンとして除外される単語は、以下の通りである。

\begin{itemize}
    \item Javaパッケージ名: "java", "util", "lang", "io", "net", "org", "com", "javax"
    \item メソッドの接頭辞: "get", "set", "is", "has"
    \item 動詞: "create", "build", "make", "run", "execute"
    \item Javaの予約語や型名: "class", "interface", "void", "int", "string"
    \item 修飾語: "impl", "default", "base", "simple", "empty"
\end{itemize}

これらのトークンは、多くのプロジェクトで頻出するため識別能力が低く、予測モデルにノイズをもたらす。一方、"validate"、"parser"、"socket"といった単語は、メソッドの具体的な機能を示し、欠陥予測に有用である。

抽出されたトークンは、TF-IDF（Term Frequency-Inverse Document Frequency）を用いて数値ベクトルに変換される。TF-IDFは、各トークンの重要度を、文書内での出現頻度と全文書での出現頻度の逆数の積として計算する。これにより、特定のメソッドに特徴的なトークンに高い重みが付与され、多くのメソッドに共通するトークンの重みは抑制される。この処理により、メソッドが属するパッケージやクラスの名前、メソッド名自体が持つ類似性に基づく情報を特徴量として活用できる。

\paragraph{異なる構成要素の特徴量の活用}
最終的に、以下の特徴量を組み合わせてモデルの入力とする。

\begin{itemize}
    \item BugHunterデータセットに元々含まれる構造的メトリクス
    \item メソッド単位の変更メトリクス
    \item コミット単位の変更メトリクス
    \item メソッドの操作タイプ
    \item メソッドの識別子に含まれる特徴的な要素
\end{itemize}

\paragraph{データ前処理とメトリクス計算の実装手順}
前述した特徴量を実際のデータセットに適用するため、データの前処理とメトリクスの計算を実施する。データセット構築のために実行した一連のプログラムとその処理内容を表\ref{tab:data_processing_summary} に示す。

\begin{table}[htbp]
  \centering
  \caption{データセット構築に使用したプログラムとその処理内容}
  \label{tab:data_processing_summary}
  \begin{tabular}{|l|p{8cm}|}
    \hline
    \textbf{プログラム名} & \textbf{処理内容} \\ \hline
    drop\_columns.py & 全ての値が0であるカラムを削除する \\ \hline
    drop\_rows.py & 分析対象外のレコード（外部ライブラリに属するメソッドなど）を削除する \\ \hline
    add\_method\_level\_metrics.py & メソッド単位のメトリクスを取得し、直前のコミットとの差分を計算する \\ \hline
    add\_commit\_level\_metrics.py & コミット単位のメトリクスを取得し、直前のコミットとの差分を計算する \\ \hline
  \end{tabular}
\end{table}

まず、BugHunterデータセットから取得した生データに対して前処理を行う。drop\_columns.pyを用いて全ての値が0であるカラムを削除し、drop\_rows.pyを用いて分析対象外のレコード（例: 外部ライブラリに属するメソッド）を削除する。

前処理後のデータに対して、メソッド単位の変更メトリクスを追加する。add\_method\_level\_metrics.pyを実行し、各メソッドについて欠陥混入コミットあるいは欠陥修正コミットとその直前のコミットにおけるコード行数、トークン数、循環的複雑度を取得し、これらの差分を計算する。

続いて、コミット単位の変更メトリクスを追加する。add\_commit\_level\_metrics.pyを実行し、各コミットについて変更されたファイル数、コードの追加行数、コードの削除行数、変更の広がりを取得し、これらの差分を計算する。これらのメトリクスは、GitリポジトリからGitPythonライブラリを用いて計算される。変更の広がりについては、Hassanの手法\cite{hassan2009}に基づき、情報理論のエントロピーを用いて変更の分散度を求める。

これらのプログラムは順次実行され、各ステップの出力が次のステップの入力となる。具体的には、drop\_columns.py → drop\_rows.py → add\_method\_level\_metrics.py → add\_commit\_level\_metrics.pyの順に実行することで、最終的なデータセットが構築される。これらのプログラムを含むリポジトリは参考文献に記載されている\cite{replication_package}。