3.2節で定義した変更メトリクスを実際のデータセットに適用するため、以下の実装を行う。

\paragraph{メソッド単位の変更メトリクスの計算}
メソッド単位の変更メトリクスとして、コード行数の変化量、トークン数の変化量、循環的複雑度の変化量を算出する。これらは、同一メソッドの欠陥混入時とその1つ前のコミットの値の差分として計算される。

具体的には、BugHunterデータセットに含まれる各メソッドについて、欠陥混入コミット（または修正コミット）における値と、その直前のコミットにおける値を取得し、以下の計算を行う。

\begin{itemize}
    \item コード行数の変化量 = 現在のコミットのコード行数 - 直前のコミットのコード行数
    \item トークン数の変化量 = 現在のコミットのトークン数 - 直前のコミットのトークン数
    \item 循環的複雑度の変化量 = 現在のコミットの循環的複雑度 - 直前のコミットの循環的複雑度
\end{itemize}

これらの変化量は、メソッドがどの程度変更されたかを直接的に表現する指標となる。

\paragraph{コミット単位の変更メトリクスの計算}
コミット単位の変更メトリクスとして、変更されたファイル数（NF）、追加行数の割合（LA/LT）、削除行数の割合（LD/LT）、1ファイル当たりの平均行数（LT/NF）を生成する。これらは、BugHunterデータセットに含まれるコミット情報から以下のように計算される。

\begin{itemize}
    \item 変更されたファイル数（NF）: コミットで変更されたファイルの総数
    \item 追加行数の割合（LA/LT）: $\frac{\text{追加行数}}{\text{変更前の総行数}}$
    \item 削除行数の割合（LD/LT）: $\frac{\text{削除行数}}{\text{変更前の総行数}}$
    \item 1ファイル当たりの平均行数（LT/NF）: $\frac{\text{変更対象ファイルの総行数}}{\text{変更ファイル数}}$
\end{itemize}

これらの変化率ベースのメトリクスは、コミット全体での変更の影響範囲や性質を捉える。

\paragraph{メソッドの操作タイプのラベル付与}
メソッドの操作タイプ(追加、変更、削除)は、欠陥混入リスクと密接に関連している。この特徴量を含める理由は以下の通りである。第一に、操作の種類によって欠陥混入の傾向が異なる。新規追加されたメソッド(Add)は、既存コードとの統合時に予期しない相互作用を引き起こす可能性がある。既存メソッドの変更(Modify)は、意図しない副作用や欠陥を生む可能性がある。削除されたメソッド(Delete)は、他の箇所で依存関係が残っている場合に問題となる。第二に、先行研究において操作タイプが欠陥予測の有効な特徴量であることが示されている。例えば、新規追加コードは既存コードと比較して欠陥密度が高い傾向があることが実証されている。第三に、レビュー戦略の改善に寄与する。操作タイプを考慮することで、新規追加コードには統合テストを重視し、既存コードの変更には回帰テストを重視するなど、レビューアプローチを調整できる。



各メソッドに対して、そのメソッドが追加、変更、削除のいずれの操作を受けたかを示すラベルを付与する。これらの操作タイプは、欠陥混入コミットあるいは欠陥修正コミットと、その直前のコミットを比較することで判定される。

\begin{itemize}
    \item 追加（Add）
    \begin{itemize}
        \item 直前のコミットには存在せず、当該コミットで新たに追加されたメソッド
    \end{itemize}
    \item 変更（Modify）
    \begin{itemize}
        \item 直前のコミットと当該コミットの両方に存在し、内容が変更されたメソッド
    \end{itemize}
    \item 削除（Delete）
    \begin{itemize}
        \item 直前のコミットには存在したが、当該コミットで削除されたメソッド
    \end{itemize}
\end{itemize}

これらのラベルは、カテゴリカル変数として扱い、One-Hotエンコーディングを用いて数値ベクトルに変換する。例えば、「追加」は [1, 0, 0]、「変更」は [0, 1, 0]、「削除」は [0, 0, 1] のようにエンコードされる。

\paragraph{メソッド識別子の処理}
メソッドの完全修飾名を特徴量として利用する理由は、識別子に含まれる意味的情報が欠陥傾向を反映するためである。具体的には、以下の知見に基づいている。第一に、メソッド名やクラス名には機能を示す単語が含まれる。例えば、"parse"、"serialize"、"validate"といった単語を含むメソッドは、入力検証やデータ変換に関わるため、エッジケースの処理ミスによる欠陥が発生しやすい。"init"や"constructor"を含むメソッドは、初期化ロジックの誤りによる欠陥が多い傾向がある。第二に、パッケージ構造が示す情報である。特定のパッケージ(例えば、ネットワーク処理やデータベース接続)に属するメソッドは、外部リソースとの相互作用に起因する欠陥が発生しやすい。第三に、コードメトリクスだけでは捉えられない文脈情報を補完する。同じ複雑度を持つメソッドでも、その役割や責務によって欠陥リスクが異なる可能性がある。これらの理由から、識別子のトークン化は予測精度の向上に寄与すると期待される。

メソッドの完全修飾名（例: org.elasticsearch.index.fielddata.plain.GeoPointDoubleArrayAtomicFieldData\$Empty.<init>()V）は、そのままでは機械学習モデルに入力できないため、トークン分割を行う。

具体的には、以下の手順で処理する。

第一に、正規表現を用いてメソッドシグネチャからパッケージ名、クラス名、メソッド名を抽出する。

第二に、パッケージ名を.で分割し、各部分をトークンとする。例えば、"org.elasticsearch.index"は["org", "elasticsearch", "index"]に分割される。

第三に、クラス名を\$で分割し、各部分をキャメルケース分割する。例えば、"GeoPointDoubleArrayAtomicFieldData"は["Geo", "Point", "Double", "Array", "Atomic", "Field", "Data"]に分割される。

第四に、メソッド名をスネークケース（\_や-）で分割した後、さらにキャメルケース分割する。ただし、<init>や<clinit>などの特殊なメソッド名は"constructor"というトークンに変換する。

第五に、全てのトークンを小文字に変換する。

さらに、"java"、"util"、"get"、"set"などのJava言語における一般的な単語や、文字数が3文字に満たない短い断片を除外する。これらを除外する理由は、高頻度で出現する単語は識別能力が低く、予測モデルにノイズをもたらすためである。例えば、"java"や"util"はほぼ全てのプロジェクトで頻出するため、欠陥の有無を区別する特徴とはならない。同様に、"get"や"set"といったアクセサメソッドの接頭辞も、メソッドの本質的な役割を示さない。これらの汎用的な単語を除外することで、"parser"、"validator"、"serializer"といった、メソッドの具体的な機能を示す有用な情報の断片のみが抽出される。これにより、特徴量の次元数を削減しながら、予測に有効な情報を保持できる。

抽出されたトークンは、語彙辞書を用いて数値インデックスに変換され、さらにベクトル表現に変換される。この処理により、メソッドが属するパッケージやクラスの名前、メソッド名自体が持つ意味的な情報を特徴量として活用できる。

\paragraph{特徴量の統合}
最終的に、以下の特徴量を統合してモデルの入力とする。

\begin{itemize}
    \item BugHunterデータセットに元々含まれるコードメトリクス
    \item メソッド単位の変更メトリクス（変化量）
    \item コミット単位の変更メトリクス（変化率）
    \item メソッドの操作タイプ（One-Hotエンコーディング）
    \item メソッド識別子のトークンベクトル
\end{itemize}

これらを組み合わせることで、コードの静的な性質、時系列変化、操作の種類、意味的な情報を包括的に捉えた特徴量セットを構築する。

\paragraph{データ前処理とメトリクス計算の実装手順}
上述した特徴量を実際のデータセットに適用するため、以下の手順でデータ前処理とメトリクス計算を実施する。

まず、BugHunterデータセットから取得した生データに対して前処理を行う。drop\_columns.pyを用いて、全ての値が0であるカラムを削除する。これらのカラムは予測に寄与しないため、モデルの複雑性を低減するために除外する。次に、drop\_rows.pyを用いて、分析対象外のレコード（例えば、外部ライブラリに属するメソッド）を削除する。Neo4jプロジェクトでは、org.apache.luceneパッケージに属するメソッドが該当する。

前処理後のデータに対して、メソッド単位の変更メトリクスを追加する。add\_method\_level\_metrics.pyを実行し、各メソッドについて、欠陥混入コミット（または修正コミット）とその直前のコミットにおけるコード行数、トークン数、循環的複雑度を取得し、これらの差分を計算する。この処理により、メソッドがどの程度変更されたかを表す変化量が特徴量として追加される。

続いて、コミット単位の変更メトリクスを追加する。add\_commit\_level\_metrics.pyを実行し、各コミットについて、変更されたファイル数、追加行数、削除行数、変更の広がりを計算する。これらのメトリクスは、GitリポジトリからGitPythonライブラリを用いてコミット間の差分を取得し算出する。変更の広がりについては、Hassanの手法\cite{hassan2009}に基づき、情報理論のエントロピーを用いて変更の分散度を定量化する。

これらのプログラムは順次実行され、各ステップの出力が次のステップの入力となる。具体的には、drop\_columns.py → drop\_rows.py → add\_method\_level\_metrics.py → add\_commit\_level\_metrics.pyの順に実行することで、最終的な特徴量セットが構築される。これらのプログラムを含む実験のレプリケーションパッケージは公開されている\cite{replication_package}。