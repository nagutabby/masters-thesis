\paragraph{従来手法の問題点}
従来のレビュー優先度付け手法では、欠陥予測モデルが出力したバグ混入確率に基づいてコミットを順位付けし、上位からレビューを行うアプローチが一般的であった。Kameiらの研究では、レビュー労力を「変更された行の総数」として計算し、総労力の一定割合（例えば20\%）を使用してレビューできるコミット数を評価している。

しかし、この手法には重要な単純化が含まれている。具体的には、レビュー労力を変更行数のみで計算しているため、変更の複雑さや影響範囲の広さが考慮されていない。実際のレビュー労力は、変更されたファイル数や変更の分散度といった要因にも依存する。例えば、10個のファイルに分散した100行の変更は、1個のファイルに集中した100行の変更よりもレビュー労力が大きいと考えられる。

さらに重要な問題として、従来手法では「レビューに必要な総労力」を全コミットのレビュー労力の和として設定している場合が多い。しかし、極端に大きなレビュー労力を要するコミット（例えば、数千行の変更を含むコミット）が存在する場合、この設定は現実的ではない。実際の開発現場では、レビューに使える労力には上限があり、その上限を超える巨大なコミットは分割されるか、別の品質保証プロセスが適用される。

\paragraph{ナップサック問題への定式化}
本研究では、レビュー対象コミットの選択をナップサック問題として定式化する。ナップサック問題は、容量制約のある袋（ナップサック）に、価値と重さを持つ複数のアイテムを入れるとき、総重量が容量を超えないように、総価値を最大化するアイテムの組み合わせを求める最適化問題である。

レビュー対象の選択問題をナップサック問題に対応付けると、以下のようになる。

\begin{itemize}
    \item アイテム: レビュー待ちの各コミット $i$（$i = 1, 2, ..., N$）
    \item アイテム数 $N$: レビュー待ちの全てのコミット数
    \item アイテムの重さ $W_i$: コミット $i$ のレビューに必要な労力
    \item アイテムの価値 $V_i$: コミット $i$ のレビューによるバグ発見期待値（モデルが予測したバグ混入確率 $\hat{y}_i$）
    \item ナップサックの容量 $C_{total}$: レビューに使える総労力
    \item 目的: レビュー労力の合計が $C_{total}$ を超えないように、レビューするコミットの組み合わせを選び、バグ発見期待値の合計 $V_{total}$ を最大化
\end{itemize}

数式で表現すると、以下の最適化問題となる。

\begin{align}
\text{maximize} \quad & \sum_{i=1}^{N} V_i x_i \\
\text{subject to} \quad & \sum_{i=1}^{N} W_i x_i \leq C_{total} \\
& x_i \in \{0, 1\}
\end{align}

ここで、$x_i$ は二値変数であり、コミット $i$ をレビューする場合は $x_i = 1$、レビューしない場合は $x_i = 0$ となる。

\paragraph{レビュー労力の計算式}
各コミット $i$ のレビュー労力 $W_i$ を計算するため、以下の要素を考慮する。

\begin{itemize}
    \item コードチャーン $C_i$: コミット $i$ における追加行数と削除行数の合計
\end{itemize}

\[
C_i = LA_i + LD_i
\]

ここで、$LA_i$ は追加されたコード行数、$LD_i$ は削除されたコード行数である。
\begin{itemize}
    \item 変更ファイル数 $N_i$: コミット $i$ で変更されたファイルの総数
    \item Entropy $H_i$: コミット $i$ における変更の分散度を表す指標
\end{itemize}

\[
H_i = -\sum_{k=1}^{n_i} p_k \log_2 p_k
\]

ここで、$n_i$ はコミット $i$ で変更されたファイル数、$p_k$ はファイル $k$ が変更全体に占める割合である。

\[
p_k = \frac{\text{file}_k \text{の変更行数}}{\text{全変更行数}}
\]

Entropyを正規化するため、以下の式を用いる。

\[
H_i^{\text{norm}} = \frac{H_i}{\log_2 n_i}
\]

この正規化により、Entropyは0から1の範囲に収まり、ファイル数が異なるコミット間での比較が可能になる。

これらの要素を組み合わせて、ベース労力 $E_{\text{raw}, i}$ を以下のように計算する。

\[
E_{\text{raw}, i} = C_i \times N_i^{H_i^{\text{norm}}}
\]

この式は、変更の規模（コードチャーン）と、変更の複雑さ（変更ファイル数とEntropy）の両方を考慮している。変更ファイル数が多いほど、またEntropyが高い（変更が複数のファイルに分散している）ほど、レビュー労力が増加する。

次に、極端に大きな値の影響を緩和するため、対数変換を適用する。

\[
W_i = E_{\text{adj}, i} = \ln(E_{\text{raw}, i} + 1)
\]

数千行の変更を含む巨大なコミットが存在する場合、ベース労力が極端に大きくなり、他のコミットの労力が相対的に無視できるほど小さくなってしまう。対数変換により、この影響を緩和し、中小規模のコミットも適切に評価できる。

\paragraph{貪欲法}
ナップサック問題を解くための代表的なアルゴリズムとして、動的計画法と貪欲法がある。

動的計画法は最適解を求めることができるが、計算量が $O(NC_{total})$ であり、容量 $C_{total}$ が大きいほど計算時間が増加する。レビュー労力の場合、$C_{total}$ は全コミットの補正済み労力の和（あるいはその一部）となるため、非常に大きな値になる可能性がある。実際に動的計画法を実装して実験を試みたところ、メモリ容量が不足し、プログラムが終了してしまった。

貪欲法は近似解を求める手法であり、計算量は $O(N \log N)$（ソートが必要な場合）である。貪欲法では、アイテムを「価値と重さの比（密度）」の降順にソートし、密度が高いものから順にナップサックに入れていく。最適解は保証されないが、計算時間が容量に依存せず、実用的な時間で解を得られる。実験では、貪欲法により数秒で処理が完了した。

本研究では、計算時間とメモリ効率を考慮し、貪欲法を採用する。

各コミット $i$ の密度 $D_i$ を以下のように定義する。

\[
D_i = \frac{V_i}{W_i} = \frac{\hat{y}_i}{E_{\text{adj}, i}}
\]

ここで、$\hat{y}_i$ はモデルが予測したコミット $i$ のバグ混入確率、$E_{\text{adj}, i}$ はコミット $i$ の補正済みレビュー労力である。

貪欲法のアルゴリズムは以下の通りである。

\begin{enumerate}
    \item 全てのコミットについて密度 $D_i$ を計算する
    \item 密度の降順にコミットをソートする
    \item 累積労力 $W_{\text{累積}} = 0$ とする
    \item ソートされた順にコミットを選択し、以下を実行する：
    \begin{itemize}
        \item $W_{\text{累積}} + W_i \leq C_{total}$ であれば、コミット $i$ をレビュー対象に追加し、$W_{\text{累積}} \leftarrow W_{\text{累積}} + W_i$ とする
        \item そうでなければ、コミット $i$ をスキップする
    \end{itemize}
    \item 累積労力が容量を超えるまで、または全てのコミットを検討するまで繰り返す
\end{enumerate}

この貪欲法により、限られたレビュー労力の中で、バグ発見期待値を効率的に最大化できる。

\paragraph{レビューに使える総労力}
ナップサックの容量 $C_{total}$（レビューに使える総労力）の設定には注意が必要である。

素朴なアプローチとして、全コミットの労力の和を $C_{total}$ とする方法が考えられる。しかし、極端に大きな労力を要するコミット（例えば、数千行の変更を含むコミット）が存在する場合、この設定は不適切である。実際の開発現場では、レビューに使える労力には上限があり、巨大なコミットは分割されるか、別の品質保証プロセスが適用される。

本研究では、以下の手順で $C_{total}$ を設定する。

\begin{enumerate}
    \item 全コミットをレビュー労力 $W_i$ の昇順にソートする
    \item 上位80\%のコミット（レビュー労力が小さい方から80\%）を選択する
    \item 選択されたコミットのレビュー労力の和を $C_{total}$ とする
\end{enumerate}

\[
C_{total} = \sum_{i \in S_{80\%}} W_i
\]

ここで、$S_{80\%}$ は労力の小さい順に並べた上位80\%のコミットの集合である。

この設定により、極端に大きな労力を要するコミット（上位20\%）の影響を除外し、より現実的なレビュー労力の制約をモデル化できる。80\%というしきい値は、実験的に決定されたものであり、プロジェクトの特性に応じて調整可能である。

\paragraph{Cost-Benefit Curveによる評価}
提案手法のレビュー労力削減効果を評価するため、Cost-Benefit Curveを用いる。Cost-Benefit Curveは、横軸に投入したレビュー労力、縦軸に発見したバグ数をプロットしたグラフである。

提案手法（労力考慮型モデル）では、密度の高い順にコミットを選択してレビューする。各コミットをレビューするごとに、累積レビュー労力と累積発見バグ数を記録し、曲線を描く。

比較対象として、ベースラインモデル（新たな特徴量を追加する前のデータセットで学習したモデル）を用いる。ベースラインモデルでも同様に密度に基づく貪欲法を適用し、レビュー対象を選択する。すなわち、ベースラインモデルが予測したバグ混入確率 $\hat{y}_i^{\text{baseline}}$ を用いて密度を計算し、密度の高い順にコミットを選択してレビューする。

この比較により、労力を考慮したコードレビューモデルという統一的な評価枠組みの中で、特徴量エンジニアリング（メソッド単位とコミット単位の変更メトリクスの追加）の効果を測定できる。提案手法がベースライン手法よりも左上に位置する曲線を描く場合、同じレビュー労力でより多くのバグを発見できることを意味し、提案した特徴量の有効性が実証される。