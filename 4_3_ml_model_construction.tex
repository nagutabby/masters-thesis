3.3節で述べたランダムフォレストを用いて、欠陥予測モデルを構築する。本節では、ランダムフォレストの実装とモデル構築に必要な準備について述べる。

\paragraph{ランダムフォレストの実装}
ランダムフォレストは、複数の決定木を構築し、それらの予測結果を集約することで高い予測精度と汎化性能を実現するアンサンブル学習手法である。

図\ref{fig:decision_tree}に決定木の構造を示す。
決定木は、各ノードにおいて特徴量の閾値に基づいてデータを分割し、葉ノードで最終的な予測クラスを出力する。
しかし、単一の決定木は訓練データに過適合しやすく、汎化性能が低下する傾向がある。

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.7\linewidth]{figures/decision_tree.pdf}
  \caption{決定木の構造}
  \label{fig:decision_tree}
\end{figure}

ランダムフォレストでは、この問題を解決するためにブートストラップサンプリングを用いる。
図\ref{fig:bootstrap_sampling}に示すように、元の訓練データセットから復元抽出により複数の異なるサンプルを生成し、各サンプルに対して独立に決定木を学習する。
この手法により、各決定木は異なるデータの特性を学習し、多様性のあるモデル集団を構築することができる。

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.85\linewidth]{figures/bootstrap_sampling.pdf}
  \caption{ブートストラップサンプリングによる訓練データの生成}
  \label{fig:bootstrap_sampling}
\end{figure}

図\ref{fig:random_forest}に、ランダムフォレストによる分類の流れを示す。
各決定木は独立に予測を行い、分類問題では多数決により最終的な予測クラスが決定される。
また、各分岐点では全特徴量ではなくランダムに選択された特徴量の部分集合のみが使用されるため、決定木間の相関がさらに低減され、モデルの汎化性能が向上する。

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.95\linewidth]{figures/random_forest_classification.pdf}
  \caption{ランダムフォレストによる分類プロセス}
  \label{fig:random_forest}
\end{figure}

\paragraph{特徴量の統合}
最終的に、以下の特徴量を統合してモデルの入力とする。

\begin{itemize}
    \item BugHunterデータセットに元々含まれるコードメトリクス（コード行数、循環的複雑度など）
    \item メソッド単位の変更メトリクス（コード行数の変化量、トークン数の変化量、循環的複雑度の変化量）
    \item コミット単位の変更メトリクス（変更ファイル数、追加行数の割合、削除行数の割合、1ファイル当たりの平均行数）
    \item メソッドの操作タイプ（追加、変更、削除のOne-Hotエンコーディング）
    \item メソッド識別子のトークンベクトル
\end{itemize}

これらを組み合わせることで、コードの静的な性質、時系列変化、操作の種類、意味的な情報を包括的に捉えた特徴量セットを構築する。

\paragraph{モデル構築の段階的アプローチ}
提案する特徴量の有効性を検証するため、段階的にモデルを構築する。この手法はablation studyと呼ばれ、機械学習研究において標準的な評価手法である。各ステップで特徴量を追加することにより、その特徴量群が予測性能にどの程度寄与するかを定量的に評価できる。具体的には、ステップ1からステップ2への改善により、メソッド単位の変更メトリクスの効果を測定し、ステップ2からステップ3への改善により、コミット単位の変更メトリクスの追加効果を測定する。この段階的評価により、以下の問いに答えることができる。(1) 時系列変化を考慮することで予測性能は向上するか、(2) メソッド単位とコミット単位の両方のメトリクスを統合することで、さらなる改善が得られるか、(3) 各特徴量群の相対的な重要性はどの程度か。これらの知見は、提案手法の理論的妥当性を裏付けるだけでなく、実務での適用時にどの特徴量を優先的に収集すべきかの指針となる。

提案手法の各要素がどの程度予測性能に寄与するかを明らかにするため、以下の3段階でモデルを構築する。

\textbf{ステップ1（ベースライン）}: 変更メトリクスを追加する前のモデル。BugHunterデータセットに元々含まれているコードメトリクスのみを特徴量として使用する。このモデルをベースラインとし、後続のモデルとの比較基準とする。

\textbf{ステップ2}: ベースラインモデルに対して、メソッド単位の変更メトリクスを追加したモデル。これにより、メソッド単位の時系列変化を考慮することの効果を評価する。

\textbf{ステップ3（提案手法）}: ステップ2のモデルに対して、さらにコミット単位の変更メトリクスを追加したモデル。これにより、ミクロ的視点とマクロ的視点を統合することの効果を評価する。

\paragraph{モデル解釈性分析のための準備}
モデルの判断基準を理解するため、以下の解釈性分析手法を準備する。

\textbf{特徴量重要度}: ランダムフォレストが提供する特徴量重要度は、各特徴量が決定木の分岐においてどの程度情報利得をもたらしたかを示す指標である。この値を計算することで、どの特徴量が欠陥予測に重要であるかを定量的に評価できる。

\textbf{Partial Dependence Plot（PDP）}: PDPは、特定の特徴量の値を変化させたときのモデルの予測値の平均的な変化を可視化する手法である。
図\ref{fig:pdp}に示すように、特徴量$x_s$に対するPartial Dependence関数は、他の特徴量の値を固定した状態で$x_s$を変化させた際の予測値の平均として計算される。

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.9\linewidth]{figures/partial_dependence_plot.pdf}
  \caption{Partial Dependence Plotの計算方法}
  \label{fig:pdp}
\end{figure}

特徴量$x_s$に対するPartial Dependence関数$\hat{f}_{x_s}$は以下のように定義される:

\begin{equation}
\hat{f}_{x_s}(x_s) = \frac{1}{n}\sum_{i=1}^{n}\hat{f}(x_s, \mathbf{x}_{\backslash s}^{(i)})
\end{equation}

ここで、$\hat{f}$は学習されたモデル、$\mathbf{x}_{\backslash s}^{(i)}$は$i$番目のサンプルにおける特徴量$x_s$以外の特徴量の値を表す。

\textbf{決定木の可視化}: ランダムフォレストを構成する決定木の一つを可視化することで、どのような分類条件で欠陥の有無を判断しているかを確認できる。