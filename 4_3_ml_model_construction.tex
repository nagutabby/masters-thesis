3.3節で述べたランダムフォレストを用いて、欠陥予測モデルを構築する。本節では、ランダムフォレストの実装とモデル構築に必要な準備について述べる。

\paragraph{ランダムフォレストの実装}
ランダムフォレストは、複数の決定木を構築し、それらの予測結果を集約することで高い予測精度と汎化性能を実現するアンサンブル学習手法である。

図\ref{fig:decision_tree}に決定木の構造を示す。決定木は、各ノードにおける特徴量のしきい値に基づいてデータを分割し、葉ノードで最終的な予測クラスを出力する。しかし、単一の決定木は訓練データを過学習しやすく、汎化性能が低下する傾向がある。

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.7\linewidth]{figures/decision_tree.pdf}
  \caption{決定木の構造}
  \label{fig:decision_tree}
\end{figure}

ランダムフォレストでは、この問題を解決するためにブートストラップサンプリングを用いる。図\ref{fig:bootstrap_sampling}に示すように、元の訓練データセットから復元抽出により複数の異なるサンプルを生成し、各サンプルに対して独立に決定木を学習する。

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.85\linewidth]{figures/bootstrap_sampling.pdf}
  \caption{ブートストラップサンプリングによる訓練データの生成}
  \label{fig:bootstrap_sampling}
\end{figure}

図\ref{fig:random_forest}に、ランダムフォレストによる分類の流れを示す。各決定木は独立に予測を行い、分類問題では多数決により最終的な予測クラスが決定される。また、各分岐点ではランダムに選択された特徴量の部分集合のみが使用されるため、決定木間の相関が低減され、モデルの汎化性能が向上する。

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.95\linewidth]{figures/random_forest_classification.pdf}
  \caption{ランダムフォレストによる分類}
  \label{fig:random_forest}
\end{figure}

\paragraph{モデル構築の段階的アプローチ}
提案する特徴量の有効性を検証するため、段階的にモデルを構築する。各ステップで特徴量を追加することにより、その特徴量群が予測性能にどの程度寄与するかを定量的に評価可能である。

以下の3段階でモデルを構築する。

\textbf{ステップ1（既存手法）}: BugHunterデータセットに元々含まれている構造的メトリクスのみを特徴量として使用する。このモデルを既存手法のモデル（後続のモデルとの比較基準）とする。

\textbf{ステップ2}: 既存手法のモデルに対して、メソッド単位の変更メトリクスを追加する。これにより、メソッド単位の時系列変化を考慮することの効果を評価する。

\textbf{ステップ3（提案手法）}: ステップ2のモデルに対して、さらにコミット単位の変更メトリクスを追加する。これにより、局所的な観点と全体的な観点の分析を組み合わせた場合の効果を評価する。

この段階的評価により、1）時系列変化を考慮することで予測性能は向上するか、2）メソッド単位とコミット単位のメトリクスを活用することで、さらなる改善が得られるか、3）各特徴量群の相対的な重要性はどの程度かが明らかになる

\paragraph{モデルのクラス分類の分析手法}
モデルのクラス分類を理解するため、以下の分析手法を準備する。

\textbf{特徴量重要度}: ランダムフォレストが提供する特徴量重要度は、各特徴量が決定木の分岐においてどの程度情報利得をもたらしたかを示す指標である。この値により、どの特徴量が欠陥予測に重要であるかを定量的に評価可能である。

\textbf{Partial Dependence Plot（PDP）}: PDPは、特定の特徴量の値を変化させたときのモデルの予測値の平均的な変化を可視化する手法である。図\ref{fig:pdp}に示すように、特徴量$x_s$に対するPartial Dependence関数は、他の特徴量の値を固定した状態で$x_s$を変化させた際の予測値の平均として計算される。

\begin{figure}[tb]
  \centering
  \includegraphics[width=0.9\linewidth]{figures/partial_dependence_plot.pdf}
  \caption{Partial Dependence Plotの計算方法}
  \label{fig:pdp}
\end{figure}

特徴量$x_s$に対するPartial Dependence関数$f_{\text{PD}}(x_s)$は以下のように定義される。

$$f_{\text{PD}}(x_s) = \frac{1}{n}\sum_{i=1}^{n}\hat{f}(x_s, x_{-s}^{(i)})$$

ここで、$\hat{f}$は学習されたモデル、$x_{-s}^{(i)}$は$i$番目のサンプルにおける特徴量$x_s$以外の特徴量の値を表す。

\textbf{決定木の可視化}: ランダムフォレストを構成する決定木の一つを可視化することで、どのような分類条件で欠陥の有無を判断しているかを確認することが可能である。