\subsection{評価手順}
本研究では、提案する変更メトリクスの各要素が予測性能に与える影響を明確にするため、段階的な評価を実施する。本節では、評価手順を順に述べる。

\paragraph{データ分割}
まず、各プロジェクトのデータセットを訓練データ80\%、テストデータ20\%に分割する。訓練データはモデルの学習に使用し、テストデータは最終的な性能評価に使用する。テストデータは訓練過程で一切使用しないため、未知データに対する汎化性能を測定可能である。

\paragraph{10分割交差検証}
次に、訓練データに対して10分割交差検証を実施し、モデルの安定性を評価する。交差検証は、データセットを複数のサブセットに分割し、それぞれのサブセットを訓練データあるいは評価データとして用いる手法である。モデルを訓練し、検証データでF1スコア、適合率、再現率を計算する。この過程をサブセットの数だけ繰り返し、各サブセットが1度だけ検証データとして使用されるようにする。交差検証で得られた全ての評価結果の平均値と標準偏差を算出する。標準偏差が小さいほど、データの分割方法に依存しない安定したモデルであることを示す。

\paragraph{評価指標}
評価指標として、3.3節で定義した適合率、再現率、F1スコア、およびAUC（Area Under the Curve）を用いる。適合率は欠陥を含むと予測したコミットのうち実際に欠陥を含む割合、再現率は実際に欠陥を含むコミットのうち正しく予測できた割合を示す。F1スコアは適合率と再現率の調和平均であり、陽性クラス（欠陥を含むコミット）と陰性クラス（欠陥を含まないコミット）の不均衡が大きいデータセットにおいて、モデルの総合的な予測性能を評価するのに適している。AUCは分類器の性能をしきい値によらず評価する指標であり、1に近いほど性能が高い。

\paragraph{最終評価}
交差検証により性能が確認されたモデルを、訓練データ全体で再学習する。その後、このモデルをテストデータに適用し、最終的な性能指標を算出する。

\paragraph{段階的評価の実施}
評価は以下の3段階で実施する。第1段階（既存手法、ステップ1）ではBugHunterデータセットの元のメトリクスのみを使用する。これは構造的メトリクスを中心とした特徴量である。第2段階（ステップ2）ではメソッド単位の変更メトリクスを追加する。これには、メソッドの変更タイプ（追加、削除、修正）やメソッド単位のコード行数の変化量などが含まれる。第3段階（提案手法、ステップ3）ではコミット単位の変更メトリクスをさらに追加する。これには、コミットの変更ファイル数、追加・削除コード行数などが含まれる。各段階の評価結果を比較することで、メソッド単位とコミット単位の変更メトリクスがそれぞれどの程度性能向上に寄与するかを明らかにする。

\paragraph{統計的有意性の検証}
提案手法（ステップ3）と既存手法（ステップ1）の機械学習モデルの性能差が統計的に有意であることを、McNemar検定により検証する。McNemar検定は、同じテストデータに対する2つの分類器の予測結果を比較する検定手法である。この検定では、まず2つのモデルの予測結果から分割表を作成する。分割表では、既存手法で正分類であり提案手法で誤分類であったサンプル数を$n_{12}$、提案手法で正分類であり既存手法で誤分類であったサンプル数を$n_{21}$とする。検定統計量は以下で計算される。

\[
\chi^2 = \frac{(n_{12} - n_{21})^2}{n_{12} + n_{21}}
\]

有意水準0.05で、$p < 0.05$の場合に性能差が統計的に有意であると判断する。

\paragraph{レビュー労力削減効果の評価}
提案手法によるレビュー労力削減効果を評価するため、レビュー労力に対する欠陥発見数の累積曲線を作成する。累積曲線は、横軸に投入したレビュー労力、縦軸に発見した欠陥数をプロットしたグラフである。提案手法の曲線が既存手法より左上に位置する場合、同じ労力でより多くの欠陥を発見可能であることを意味する。

\paragraph{貪欲法によるレビュー対象の選択}
累積曲線を作成するため、各モデル（ステップ1、ステップ2、ステップ3）について、貪欲法によりレビュー対象コミットを選択する。貪欲法は、各段階で局所的に最適な選択を行うアルゴリズムである。このアルゴリズムでは、まず各コミット$i$のレビュー労力を4.4節の方法で計算する。次に、全コミットをレビュー労力の昇順にソートし、上位80\%のコミットの労力の和を総労力$C_{total}$として設定する。各コミット$i$について、モデルが予測した欠陥混入確率$\hat{y}_i$と補正済み労力$W_i$から密度を計算する。

\[
D_i = \frac{\hat{y}_i}{W_i}
\]

密度$D_i$の降順にコミットをソートする。累積労力$W_{\text{total}} = 0$とする。ソートされた順にコミットを検討し、$W_{\text{total}} + W_i \leq C_{total}$であればコミット$i$をレビュー対象に追加し、$W_{\text{total}} \leftarrow W_{\text{total}} + W_i$とする。そうでなければスキップする。累積労力が容量を超えるまで、または全コミットを検討するまで繰り返す。各コミットをレビューするごとに、累積レビュー労力と累積欠陥発見数を記録する。この手順により、少ないレビュー労力で欠陥発見期待値を最大化するレビュー対象を選択することが可能である。

\paragraph{累積曲線の作成}
累積曲線は以下の手順で作成する。各モデルについて、貪欲法によりレビュー対象コミットを選択する。各コミットをレビューする順に、累積レビュー労力と累積欠陥発見数を記録する。横軸を累積レビュー労力、縦軸を累積欠陥発見数として、各モデルの曲線を同一グラフ上に描画する。総労力の20\%, 40\%時点での欠陥発見数を比較する。

\paragraph{評価指標の定義}
評価指標として、欠陥発見率と改善幅を用いる。欠陥発見率は、特定労力時点までに発見した欠陥の数を全欠陥数で割った値であり、以下の式で定義される。

\[
\text{欠陥発見率} = \frac{\text{発見した欠陥の数}}{\text{全欠陥数}} \times 100
\]

改善幅は、提案手法（ステップ3）と既存手法（ステップ1）の欠陥発見率の差であり、以下の式で定義される。

\[
\text{改善幅} = \text{提案手法の欠陥発見率} - \text{既存手法の欠陥発見率}
\]

\paragraph{特徴量重要度の算出}
ランダムフォレストが提供する特徴量重要度を用いて、各特徴量の予測への寄与度を定量化する。特徴量重要度は、各特徴量が決定木の分岐においてどの程度情報利得をもたらしたかを示す指標である。情報利得は、ある特徴量で分岐することにより、データの不純度（通常、ジニ不純度で表される）がどの程度減少するかを測る指標である。ランダムフォレストでは、全ての決定木における各特徴量の情報利得の平均を計算することで特徴量重要度を算出する。本研究では、この指標を用いて、訓練済みの機械学習モデルから各特徴量の重要度を取得する。さらに、各特徴量を特徴量重要度の降順にソートする。上位の特徴量を抽出し、棒グラフで可視化する。これにより、メソッド単位、コミット単位、元のメトリクスという各カテゴリーの特徴量がどの程度重要であるかを分析する。

\paragraph{Partial Dependence Plotの生成}
各特徴量と欠陥混入確率の関係を可視化するため、Partial Dependence Plot（PDP）を生成する。PDPは、特定の特徴量の値を変化させたときに、モデルの予測値がどのように変化するかを示すグラフである。特徴量$x_s$に対するPartial Dependence関数$f_{\text{PD}}(x_s)$を求めるには、まず特徴量$x_s$の値を固定値に設定する。他の全ての特徴量$x_{-s}$は、各サンプルの実際の値を使用する。全サンプルについて予測値を計算し、その平均を取る。

\[
f_{\text{PD}}(x_s) = \frac{1}{n}\sum_{i=1}^{n}\hat{f}(x_s, x_{-s}^{(i)})
\]

特徴量$x_s$の値を変化させながらこの計算を繰り返す。この結果、横軸を特徴量$x_s$の値、縦軸を予測確率とするグラフが得られる。このグラフを用いることで、特定の特徴量が増加した際に欠陥混入確率がどのように変化するかを視覚的に理解することが可能になる。このグラフを生成するために、まず特徴量重要度が上位の特徴量を選択する。各特徴量の値の範囲を等間隔に分割する。各点において上記の計算方法でPartial Dependence値を計算する。横軸を特徴量の値、縦軸を予測確率として、各特徴量のPDPをグラフ化する。

\paragraph{決定木の可視化}
ランダムフォレストを構成する決定木の構造を可視化し、どのような分類条件で欠陥の有無を判断しているかを確認する。決定木の構造を可視化するには、まずランダムフォレストから代表的な決定木を1つ選択する。決定木の各ノードにおける分岐条件（特徴量としきい値）を抽出する。各ノードのサンプル数とクラス分布を取得する。グラフ描画ライブラリを用いて、決定木を描画する。