本節では、4章で構築した実験環境を用いて、提案手法の有効性を評価する方法について述べる。評価は、予測性能の評価、レビュー工数削減効果の評価、モデル解釈性の分析の3つの観点から実施する。

\subsection{予測性能の評価手順}

\paragraph{データ分割}
各プロジェクトのデータセットを訓練データとテストデータに分割する。訓練データはモデルの学習に使用し、テストデータは最終的な性能評価に使用する。データセットの分割比率は、訓練データ80\%、テストデータ20\%とする。

この分割により、モデルが訓練データに過適合していないかを検証し、未知のデータに対する汎化性能を評価できる。

\paragraph{10分割交差検証}
訓練データに対して10分割交差検証を実施し、モデルの性能の誤差を測定する。

交差検証の手順は以下の通りである。

\begin{enumerate}
    \item 訓練データを10個のサブセット（フォールド）に分割する
    \item そのうち9個を訓練用、1個を検証用として使用する
    \item この過程を10回繰り返し、各サブセットが1度だけ検証データとして使用されるようにする
    \item 各フェーズでF1スコア、適合率、再現率を計算する
    \item 10回の評価結果の平均値と標準偏差を算出する
\end{enumerate}

交差検証により、データの分割方法による性能のばらつきを評価し、モデルの安定性を確認できる。

\paragraph{評価指標}
モデルの性能を評価するため、以下の指標を使用する。

\textbf{F1スコア}: 適合率（Precision）と再現率（Recall）の調和平均。

\[
\text{F1スコア} = 2 \times \frac{\text{適合率} \times \text{再現率}}{\text{適合率} + \text{再現率}}
\]

\textbf{適合率（Precision）}: バグありと予測したもののうち、実際にバグがあった割合。

\[
\text{適合率} = \frac{\text{True Positive}}{\text{True Positive} + \text{False Positive}}
\]

\textbf{再現率（Recall）}: 実際にバグがあるもののうち、バグありと予測できた割合。

\[
\text{再現率} = \frac{\text{True Positive}}{\text{True Positive} + \text{False Negative}}
\]

\textbf{正解率（Accuracy）}: 全予測のうち、正しく分類できた割合。

\[
\text{正解率} = \frac{\text{True Positive} + \text{True Negative}}{\text{全サンプル数}}
\]

\textbf{ROC-AUC}: ROC曲線の下の面積。モデルの識別能力を示す指標で、1に近いほど性能が高い。

ソフトウェア欠陥予測においては、バグありクラスとバグなしクラスの不均衡が存在するため、F1スコアを主要な評価指標として用いる。

\paragraph{最終評価}
交差検証により性能が確認されたモデルを、訓練データ全体で再学習する。その後、このモデルをテストデータに適用し、F1スコア、適合率、再現率、正解率、ROC-AUCを算出する。この値を各モデルの最終的な性能指標とする。

テストデータは訓練・検証の過程で一切使用していないため、この評価により、完全に未知のデータに対するモデルの汎化性能を測定できる。

\paragraph{段階的評価の手順}
4.3節で述べた3段階のモデル（ベースライン、ステップ2、ステップ3）それぞれについて、上記の評価手順を実施する。

\begin{enumerate}
    \item ベースライン（ステップ1）の評価
    \begin{itemize}
        \item BugHunterデータセットの元のメトリクスのみを使用
        \item 10分割交差検証による性能評価
        \item テストデータによる最終評価
    \end{itemize}
    \item ステップ2の評価
    \begin{itemize}
        \item メソッド単位の変更メトリクスを追加
        \item 10分割交差検証による性能評価
        \item テストデータによる最終評価
    \end{itemize}
    \item ステップ3（提案手法）の評価
    \begin{itemize}
        \item コミット単位の変更メトリクスをさらに追加
        \item 10分割交差検証による性能評価
        \item テストデータによる最終評価
    \end{itemize}
\end{enumerate}

各段階の評価結果を比較することで、メソッド単位の変更メトリクスとコミット単位の変更メトリクスがそれぞれどの程度性能向上に寄与するかを明らかにする。

\paragraph{統計的有意性の検証}
提案手法（ステップ3）とベースライン（ステップ1）の予測結果に統計的に有意な差があるかを検証するため、マクネマー検定を実施する。

マクネマー検定は、同じテストデータに対する2つの分類器の予測結果を比較するための統計的検定手法である。具体的には、以下の分割表を作成する。

\begin{table}[h]
\centering
\begin{tabular}{|l|c|c|}
\hline
 & 提案手法:正解 & 提案手法:不正解 \\
\hline
ベースライン:正解 & $n_{11}$ & $n_{12}$ \\
ベースライン:不正解 & $n_{21}$ & $n_{22}$ \\
\hline
\end{tabular}
\end{table}

有意水準を0.01とし、p値が0.01未満の場合に有意な差があると判断する。

マクネマー検定により、提案手法による予測性能の改善が偶然ではなく、統計的に有意であることを確認できる。

\subsection{レビュー工数削減効果の評価手順}

\paragraph{評価の概要}
提案手法によるレビュー労力削減効果を評価するため、Cost-Benefit Curveを作成する。Cost-Benefit Curveは、横軸に投入したレビュー労力、縦軸に発見したバグ数をプロットしたグラフである。

この曲線により、限られたレビュー労力の中で、どれだけ効率的にバグを発見できるかを視覚的に評価できる。提案手法がベースライン手法よりも左上に位置する曲線を描く場合、同じレビュー労力でより多くのバグを発見できることを意味する。

\paragraph{貪欲法によるレビュー対象の選択手順}
各モデル（ベースライン、ステップ2、ステップ3）について、以下の手順でレビュー対象を選択する。

\begin{enumerate}
    \item 4.4節で述べた方法に従い、各コミット $i$ のレビュー労力 $W_i$ を計算する
    \item 全コミットをレビュー労力 $W_i$ の昇順にソートし、上位80\%のコミットの労力の和を、レビューに使える総労力 $C_{total}$ として設定する
    \item 各コミット $i$ について、モデルが予測したバグ混入確率 $\hat{y}_i$ と補正済み労力 $E_{\text{adj}, i}$ から密度 $D_i$ を計算する
    \[
    D_i = \frac{V_i}{W_i} = \frac{\hat{y}_i}{E_{\text{adj}, i}}
    \]
    \item 密度 $D_i$ の降順にコミットをソートする
    \item 累積労力 $W_{\text{累積}} = 0$ とする
    \item ソートされた順にコミットを選択し、以下を実行する：
    \begin{itemize}
        \item $W_{\text{累積}} + W_i \leq C_{total}$ であれば、コミット $i$ をレビュー対象に追加し、$W_{\text{累積}} \leftarrow W_{\text{累積}} + W_i$ とする
        \item そうでなければ、コミット $i$ をスキップする
    \end{itemize}
    \item 累積労力が容量を超えるまで、または全てのコミットを検討するまで繰り返す
    \item 各コミットをレビューするごとに、累積レビュー労力と累積発見バグ数を記録する
\end{enumerate}

この貪欲法により、限られたレビュー労力の中で、バグ発見期待値を効率的に最大化するレビュー対象を選択できる。

\paragraph{Cost-Benefit Curveの作成手順}
上記の貪欲法で得られた累積レビュー労力と累積発見バグ数のデータを用いて、Cost-Benefit Curveを描画する。

\begin{enumerate}
    \item 各モデル（ベースライン、ステップ2、ステップ3）について、貪欲法によりレビュー対象を選択する
    \item 各コミットをレビューする順に、累積レビュー労力と累積発見バグ数を記録する
    \item 横軸を累積レビュー労力、縦軸を累積発見バグ数として、各モデルの曲線を同一グラフ上に描画する
    \item 特定の労力時点（例: 20\%, 40\%, 60\%）でのバグ発見数を比較する
\end{enumerate}

\paragraph{評価指標}
Cost-Benefit Curveに加えて、以下の指標を用いて評価を行う。

\textbf{特定労力時点でのバグ発見数}: 総労力の20\%、40\%、60\%時点で発見できたバグ数を比較する。これにより、限られたレビューリソースを使用する実開発現場での効果を評価できる。

\textbf{バグ検出率}: 特定労力時点で発見したバグ数を、全バグ数で割った値。

\[
\text{バグ検出率} = \frac{\text{発見バグ数}}{\text{全バグ数}} \times 100\%
\]

\textbf{改善幅}: 提案手法（ステップ3）とベースラインのバグ検出率の差。

\[
\text{改善幅} = \text{提案手法のバグ検出率} - \text{ベースラインのバグ検出率}
\]

\textbf{AUC（Area Under Curve）}: Cost-Benefit Curveの下の面積。大きいほど効率的にバグを発見できることを示す。

\subsection{モデル解釈性の分析手順}

\paragraph{特徴量重要度の算出手順}
ランダムフォレストが提供するFeature Importanceを計算し、どの特徴量が予測に最も寄与しているかを明らかにする。

\textbf{計算方法}: Feature Importanceは、各特徴量が決定木の分岐においてどの程度情報利得（ジニ不純度の減少）をもたらしたかを示す指標である。ランダムフォレストでは、全ての決定木における各特徴量の情報利得の平均を計算することで、Feature Importanceを算出する。

\textbf{分析手順}:
\begin{enumerate}
    \item 訓練済みのランダムフォレストモデルから、各特徴量のFeature Importanceを取得する
    \item 重要度の高い順に特徴量をソートする
    \item 上位20個の特徴量を抽出し、棒グラフで可視化する
    \item メソッド単位の変更メトリクス、コミット単位の変更メトリクス、元のコードメトリクスのそれぞれがどの程度重要であるかを分析する
\end{enumerate}

\paragraph{Partial Dependence Plot（PDP）の生成手順}
各特徴量と陽性予測確率（バグあり確率）の関係を可視化するため、PDPを生成する。

\textbf{計算方法}: PDPは、特定の特徴量の値を変化させたときのモデルの予測値の平均的な変化を示す。4.3節で述べたように、特徴量$x_s$に対するPartial Dependence関数$\hat{f}_{x_s}$は以下のように計算される:

\begin{equation}
\hat{f}_{x_s}(x_s) = \frac{1}{n}\sum_{i=1}^{n}\hat{f}(x_s, \mathbf{x}_{\backslash s}^{(i)})
\end{equation}

\textbf{生成手順}:
\begin{enumerate}
    \item 重要度の高い特徴量（上位10個）を選択する
    \item 各特徴量について、その値の範囲を等間隔に分割する
    \item 各点において、他の特徴量を固定したまま、対象特徴量のみを変化させて予測を行う
    \item 全サンプルについて予測値の平均を計算し、PDPを描画する
    \item 横軸を特徴量の値、縦軸を予測確率として、各特徴量のPDPをグラフ化する
\end{enumerate}

\paragraph{決定木の可視化手順}
ランダムフォレストを構成する決定木の一つを可視化し、どのような分類条件でバグの有無を判断しているかを確認する。

\textbf{可視化手順}:
\begin{enumerate}
    \item ランダムフォレストから代表的な決定木を1つ選択する
    \item 決定木の各ノードにおける分岐条件（特徴量としきい値）を抽出する
    \item 各ノードのサンプル数、クラス分布、ジニ不純度を取得する
    \item グラフ描画ライブラリを用いて、決定木を視覚化する
\end{enumerate}