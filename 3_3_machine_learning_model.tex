本研究では、3.1節と3.2節で設計した時系列変化を考慮したメトリクスを用いて欠陥予測モデルを構築する。機械学習アルゴリズムとしてランダムフォレストを採用し、モデルの性能を評価する。

\paragraph{ランダムフォレストの採用}
ランダムフォレストは、ブートストラップサンプリングにより複数の決定木を構築し、それらの予測結果を多数決で集約する手法である。ランダムフォレストを選定した理由は以下の通りである。

第一に、非線形な関係を捉える能力が高い。ソフトウェア欠陥予測において、特徴量と欠陥の有無の関係は複雑であり、単純な線形モデルでは表現できない相互作用が存在する。例えば、変更行数が少なくても変更ファイル数が多い場合は欠陥リスクが高まるといった、複数の特徴量の組み合わせによる非線形な効果を捉える必要がある。

第二に、アンサンブル学習による予測精度の安定性である。ランダムフォレストは複数の決定木の予測を集約するため、単一の決定木と比較して過学習に強く、安定した予測性能を示す。

第三に、モデルの解釈性である。欠陥予測モデルを実際の開発現場で活用するには、なぜそのコミットが欠陥を含むと予測されたのかを理解できる必要がある。ランダムフォレストは、特徴量重要度により各特徴量の予測への寄与度を定量化でき、Partial Dependence Plot（PDP）により特定の特徴量と予測結果の関係を可視化できる。

特徴量重要度は、各特徴量が決定木の分岐においてどの程度情報利得をもたらしたかを示す指標であり、ランダムフォレストを構成する全ての決定木における情報利得の平均として算出される。この指標を用いることで、提案した変更メトリクスや従来の構造的メトリクスなど、多数の特徴量の中でどの項目が欠陥の識別に最も寄与しているかを定量的に把握することができるようになる。一方、PDPは、特定の特徴量の値を変化させた際に、モデルの予測確率が平均的にどのように変化するかを視覚化する手法である。PDPは、分析対象とする特徴量以外の変数の影響を平均化して取り除くことで、特定の特徴量と予測結果の間の関係性を抽出する。

\paragraph{評価指標}
モデルの性能評価には、不均衡データに適したF1スコアおよびROC-AUCを用いる。

F1スコアは、適合率と再現率の調和平均として以下のように定義される。

\begin{equation}
    適合率 = \frac{TP}{TP + FP}, \quad 再現率 = \frac{TP}{TP + FN}
\end{equation}
\begin{equation}
    F_1 = 2 \times \frac{適合率 \times 再現率}{適合率 + 再現率}
\end{equation}

適合率は欠陥を含むと予測したデータのうち実際に欠陥を含むデータの割合、再現率は実際に欠陥を含むデータのうち欠陥を含むと予測できた割合を表す。F1スコアは両者のバランスを評価するため、不均衡データにおいても適切な評価が可能である。F1スコアを採用する理由は、欠陥予測のために使用するデータが不均衡であるためである。一般的に、欠陥を含むメソッドやコミットの数は、欠陥を含まないメソッドやコミットの数よりも少ない。このような不均衡データでは、正解率のみでは適切な評価ができない。例えば、全てのデータを欠陥なしと予測しても、高い正確率が得られる可能性がある。

一方、ROC-AUC（Receiver Operating Characteristic-Area Under the Curve）は、分類器が陽性クラス（欠陥を含むデータ）と陰性クラス（欠陥を含まないデータ）をどの程度正確に識別できるかを示す指標である。ROC曲線は、分類のしきい値を変化させた際の真陽性率と偽陽性率の関係をプロットしたものであり、AUCはその曲線の下側の面積を表す。AUCの値は0.5から1の範囲をとり、1に近いほど高い識別性能を、0.5に近いほどランダムな予測と同等の性能であることを意味する。ROC-AUCは特定のしきい値に依存することなくモデルの全体的な識別能力を評価できるため、F1スコアと併せてモデルの有効性を多角的に検証するために用いられる。

また、データの不均衡に対処するため、本研究では学習プロセスにおいてサンプリングを行う。サンプリングとは、データの不均衡を調整し、モデルが正しく学習できるようにすることである。サンプリングには、多数派クラスのサンプル数を削減する手法や、少数派クラスのサンプル数を増加させる手法がある。これらの技術を導入する目的は、多数派である欠陥を含まないデータの特徴によって、欠陥を含むデータの特徴が学習過程で埋もれてしまうのを防ぐためである。サンプリングによってクラス間の比率を調整し、モデルに欠陥の特徴を学習する機会を適切に与えることで、正解率という表面的な数値に依存しない、識別能力の高い予測モデルを構築することを目指す。


\paragraph{統計的仮説検定}
提案手法がベースライン手法と比較して統計的に有意な改善をもたらしているかを検証するため、McNemar検定を実施する。McNemar検定は、同じデータセットに対する2つの分類器の予測結果を比較するための検定手法である。この検定により、提案手法による予測性能の改善が偶然ではなく、統計的に有意であることを確認できる。

\paragraph{交差検証}
モデルの汎化性能を評価するため、10分割交差検証を用いる。データセットを10個のサブセットに分割し、そのうち9個を訓練データ、1個をテストデータとして使用する。この過程を10回繰り返し、各サブセットが1度だけテストデータとして使用されるようにする。これにより、特定のデータ分割に依存しない頑健な性能評価が可能となる。

具体的な実装と評価手順については第4章で述べる。