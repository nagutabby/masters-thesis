本研究では、3.1節と3.2節で設計した、時系列変化を考慮したメトリクスを用いて欠陥予測モデルを構築する。機械学習アルゴリズムとしてランダムフォレストを使用し、モデルの性能を評価する。

\paragraph{ランダムフォレストの採用}
ランダムフォレストは、ブートストラップサンプリングにより複数の決定木を構築し、それらの予測結果を多数決で集約する手法である。ランダムフォレストを選定した理由は以下の通りである。

まず、非線形関係を捉える能力が高いためである。ソフトウェア欠陥予測において、特徴量と欠陥の有無の関係は複雑であり、単純な線形モデルでは表現できない相互作用が存在する。例えば、変更行数が少なくても変更ファイル数が多い場合は欠陥リスクが高まるといった、複数の特徴量の組み合わせによる非線形関係を捉える必要がある。

次に、アンサンブル学習による予測精度の安定性である。ランダムフォレストは複数の決定木の予測を集約するため、単一の決定木と比較して過学習に強く、安定した予測性能を示す。

最後に、モデルの判断基準の透明性が高いためである。欠陥予測モデルを実際の開発現場で活用するために、なぜそのコミットが欠陥を含むと予測されたのかを説明する必要がある。ランダムフォレストは、特徴量重要度を用いて各特徴量の予測への寄与度を定量化でき、Partial Dependence Plot（PDP）により特定の特徴量と予測結果の関係を可視化することが可能である。

特徴量重要度は、各特徴量が決定木の分岐においてどの程度情報利得をもたらしたかを示す指標であり、ランダムフォレストを構成する全ての決定木における情報利得の平均として算出される。この指標を用いることで、提案した変更メトリクスや従来の構造的メトリクスなど、多数の特徴量の中でどの項目が欠陥の識別に最も寄与しているかを定量的に把握することが可能になる。一方、PDPは、特定の特徴量の値を変化させた際に、モデルの予測確率が平均的にどのように変化するかを視覚化する手法である。PDPは、分析対象とする特徴量以外の変数の影響を平均化して取り除くことで、特定の特徴量と予測結果の間の関係性を抽出する。

\paragraph{評価指標}
モデルの性能を評価するための指標として、不均衡データに適したF1スコアおよびAUCを用いる。

F1スコアは、適合率と再現率の調和平均として以下のように定義される。

\begin{equation}
    適合率 = \frac{TP}{TP + FP}, \quad 再現率 = \frac{TP}{TP + FN}
\end{equation}
\begin{equation}
    F_1 = 2 \times \frac{適合率 \times 再現率}{適合率 + 再現率}
\end{equation}

適合率は欠陥を含むと予測したデータのうち実際に欠陥を含むデータの割合、再現率は実際に欠陥を含むデータのうち欠陥を含むと予測できた割合を表す。F1スコアを採用する理由は、欠陥予測のために使用するデータが不均衡であるためである。一般的に、欠陥を含むメソッドやコミットの数は、欠陥を含まないメソッドやコミットの数よりも少ない。このような不均衡データでは、正解率のみでは適切な評価ができない。例えば、全てのデータを欠陥なしと予測しても、高い正確率が得られる可能性がある。F1スコアは両者のバランスを評価するため、不均衡データに関しても適切に評価可能である。

一方、AUC（Area Under the Curve）は、分類器が陽性クラス（欠陥を含むデータ）と陰性クラス（欠陥を含まないデータ）をどの程度正確に識別可能かを示す指標である。分類のしきい値を変化させた際の真陽性率と偽陽性率の関係をプロットしたものはROC（Receiver Operating Characteristic）曲線と呼ばれ、AUCはその曲線の下側の面積を表す。AUCの値は0.5から1の範囲をとり、1に近いほど高い識別性能を、0.5に近いほどランダムな予測と同等の性能であることを意味する。AUCは特定のしきい値に依存することなくモデルの全体的な識別能力を評価可能であるため、F1スコアと併せてモデルの有効性を多角的に検証するために用いられる。

また、データの不均衡に対処するため、本研究では学習プロセスにおいてサンプリングを行う。サンプリングとは、データの不均衡を調整し、モデルの正しい学習を可能にすることである。サンプリング手法としては、多数派クラスのサンプル数を削減する手法（アンダーサンプリング）や、少数派クラスのサンプル数を増加させる手法（オーバーサンプリング）がある。これらの技術を導入する理由は、多数派クラスである欠陥を含まないデータの特徴によって、欠陥を含むデータの特徴が埋もれてしまうのを防ぐためである。サンプリングによってクラス間の比率を調整し、モデルに欠陥の特徴を学習する機会を適切に与えることで、正解率という表面的な数値に依存しない、識別能力の高い予測モデルを構築することを目指す。


\paragraph{統計的仮説検定}
提案手法が既存手法と比較して統計的に有意な改善をもたらしているかを検証するため、McNemar検定を実施する。McNemar検定は、同じデータセットに対する2つの分類器の予測結果を比較するための検定手法である。この検定により、提案手法による予測性能の改善が偶然ではなく、統計的に有意であることを確認可能である。

\paragraph{交差検証}
モデルの汎化性能を評価するため、交差検証（Cross-Validation）を用いる。この手法はデータを$k$個のサブセットに分割して評価を行うものであるが、本研究の評価においては10分割交差検証を採用する。具体的な手順は以下の通りである。まず、データセットを10個のグループに分割する。そのうち9個を訓練データ、残りの1個をテストデータとして使用し、このプロセスを合計10回繰り返す。その際、各サブセットが必ず一度ずつテストデータとして割り当てられるように構成する。このように、全てのデータをテストに使用することで、データ分割の偏りに依存しない、頑健な性能評価が可能になる。

具体的な実装と評価手順については第4章で述べる。