本章では、ソフトウェア欠陥予測に関連する研究を概観する前に、本研究で用いる主要な概念と用語について説明する。

ソフトウェアの品質を体系的に評価するため、JIS X 25010:2013\cite{jisx25010}では、製品品質モデルと利用時の品質モデルという2つの品質モデルが定義されている。製品品質モデルは、「ソフトウェアの静的特徴及びコンピュータシステムの動的特徴」に関する品質を8つの特性で分類する。これらの特性は、機能適合性、性能効率性、互換性、使用性、信頼性、セキュリティ、保守性、移植性である。各特性は更に副特性に分割され、より詳細な品質評価を可能にする。

本研究が特に注目するのは、\textbf{保守性}と\textbf{信頼性}である。保守性は「意図した保守者によって、製品又はシステムが修正することができる有効性及び効率性の度合い」と定義され、5つの副特性を持つ。\textbf{モジュール性}（一つの構成要素に対する変更が他の構成要素に与える影響が最小になる度合い）、\textbf{再利用性}（一つ以上のシステムに資産を使用することができる度合い）、\textbf{解析性}（変更の影響を総合評価すること、欠陥若しくは故障の原因を診断すること、又は修正しなければならない部分を識別することが可能であることについての有効性及び効率性の度合い）、\textbf{修正性}（欠陥の取込みも既存の製品品質の低下もなく、有効的に、かつ、効率的に製品又はシステムを修正することができる度合い）、\textbf{試験性}（試験基準を確立し、その基準が満たされているかどうかを決定するために試験を実行することができる有効性及び効率性の度合い）である。

信頼性は「明示された時間帯で、明示された条件下に、システム、製品又は構成要素が明示された機能を実行する度合い」と定義され、4つの副特性を持つ。\textbf{成熟性}（通常の運用操作の下で、システム、製品又は構成要素が信頼性に対するニーズに合致している度合い）、\textbf{可用性}（使用することを要求されたとき、システム、製品又は構成要素が運用操作可能及びアクセス可能な度合い）、\textbf{障害許容性}（ハードウェア又はソフトウェア障害にもかかわらず、システム、製品又は構成要素が意図したように運用操作できる度合い）、\textbf{回復性}（中断時又は故障時に、製品又はシステムが直接的に影響を受けたデータを回復し、システムを希望する状態に復元することができる度合い）である。

本研究では、コードの変更がこれらの品質特性、特に保守性の解析性・修正性と信頼性の成熟性にどのように影響を与えるかを分析する。コードの変化の過程を捉えることが重要である理由は、静的なスナップショットだけでは変更の勢いや不安定性を把握できないためである。例えば、ある時点でのコードメトリクスは問題なくても、短期間に頻繁な変更が繰り返されていれば、それは設計の不安定性や開発者の理解不足を示唆している可能性がある。時系列変化を分析することで、保守性を低下させる要因や、信頼性を脅かす欠陥の混入パターンを明らかにすることを目指す。

ソフトウェアの品質を定量的に評価するため、様々なコードメトリクスが提案されてきた。これらのメトリクスは、大きく3つのカテゴリーに分類できる。

\textbf{複雑度メトリクス}は、コードの構造的な複雑さを測定する。代表的なものとして、McCabeの循環的複雑度（Cyclomatic Complexity）\cite{mccabe1976}がある。これは、プログラムの制御フローグラフにおける独立したパスの数を表し、$V(G) = E - N + 2P$（$E$は辺の数、$N$は節の数、$P$は連結成分の数）として計算される。循環的複雑度が高いほど、コードの理解が困難になり、テストすべきパスが増加する。これが欠陥混入リスクを高める理由は、人間の認知的限界により、開発者が複雑なコードの全ての振る舞いを把握することが困難になり、また、テストパスの増加によってテストの網羅性が低下するためである。その結果、保守性の解析性と修正性を低下させる。

\textbf{規模メトリクス}は、コードの量的な大きさを測定する。最も基本的なメトリクスは、LOC（Lines of Code、総コード行数）である。変更規模を示すメトリクスとしては、追加されたコード行数（LA）、削除されたコード行数（LD）、変更前のファイルのコード行数（LT）などがある。規模が大きいほど、より多くのコードの変更や実装が必要となるため、欠陥が発生する可能性が高くなる。

\textbf{結合度・凝集度メトリクス}は、オブジェクト指向プログラムの構造的品質を測定する。Chidamber \& Kemerer\cite{chidamber1994}が提案したCKメトリクスは、オブジェクト指向設計の品質を評価するための標準的な指標である。CBO（Coupling Between Objects、オブジェクト間結合度）は、あるクラスが他のクラスに依存している度合いを示す。RFC（Response For Class、クラスの応答数）は、クラスが呼び出す可能性のあるメソッドの総数を示す。LCOM（Lack of Cohesion of Methods、メソッド凝集度の欠如）は、クラス内のメソッド間の凝集性の欠如を測定する。これらのメトリクスは、保守性のモジュール性や再利用性に直接影響を与える。

本研究では、これらの既存メトリクスに加えて、メソッドレベルでの時系列変化を捉えるための新しいメトリクスを提案する。

ソフトウェア工学における欠陥関連の用語は、ISO/IEC/IEEE 24765\cite{iso24765}において厳密に定義されている。\textbf{欠陥（Defect）}は、成果物が要件または仕様を満たさず、修理や交換が必要となることである。欠陥は、コード内に存在するが、必ずしも実行時に顕在化するとは限らない。\textbf{故障（Failure）}は、システムが要求された機能を実行できない事象のことである。故障は、システムの実行時に観測される異常な振る舞いであり、欠陥が顕在化した結果である。\textbf{誤り（Error）}は、人間が犯す間違いのことであり、欠陥の原因となる。

本研究では、「バグ」という用語を一般的な意味で使用するが、厳密な議論では「欠陥」という用語を用いる。また、「バグ混入コミット」または「欠陥誘発コミット」とは、後に修正が必要となる欠陥を含むコードをリポジトリに追加したコミットを指す。

欠陥混入コミットの特定には、SZZアルゴリズム\cite{sliwerski2005}を用いる。SZZアルゴリズムは、Śliwerski、Zimmermann、Zellerによって提案された手法であり、バグ修正コミットから遡って、そのバグを最初に混入させたコミットを特定する。具体的な手順は以下の通りである。まず、バグレポートシステム（例：JIRA、Bugzilla）とコミットメッセージを関連付けることで、バグ修正コミットを特定する。次に、バグ修正コミットにおいて変更された行を特定し、Gitの\texttt{git blame}機能などを用いて、それらの行が最後に修正されたコミットを遡って追跡する。この追跡によって特定されたコミットが、バグを混入させたと推定される。

本研究では、Gitなどのバージョン管理システム（VCS: Version Control System）に記録された変更履歴を分析対象とする。\textbf{コミット（Commit）}は、ソースコードへの変更をリポジトリに記録する単位である。各コミットには、変更されたファイル、追加・削除された行、コミットメッセージ、作成者、作成日時などの情報が含まれる。\textbf{差分（Diff）}は、コミット間でのファイルの変更内容を表現する方法であり、どの行が追加・削除・変更されたかを示す。

本研究がコミット単位を分析単位として選択した理由は、コミットが開発者の論理的な作業単位を表し、変更の意図やコンテキストが比較的明確であるためである。変更の文脈が明確であることは、欠陥予測において重要な意味を持つ。なぜなら、欠陥の混入は単にコード量の増加だけでなく、変更の目的や背景と密接に関係しているからである。例えば、バグ修正のための変更は新機能追加よりも欠陥を誘発しやすい傾向がある。また、レビュー時には変更の意図を理解することで、より効果的なレビューが可能になる。ファイルやパッケージ単位での予測と比較して、コミット単位での予測は以下の3つの利点がある。第一に、予測単位の粒度が小さいため、開発者は具体的にどのコード断片をレビューすべきかを特定しやすい。第二に、変更を行った開発者が明確であるため、品質保証活動の担当者を容易に割り当てることができる。第三に、開発サイクルの早い段階で予測が行われるため、開発者の記憶が新しいうちにレビューやテストを実施でき、修正コストを低減できる。

欠陥予測モデルの性能を評価するため、本研究では以下の指標を使用する。これらの指標は、\textbf{混同行列（Confusion Matrix）}に基づいて計算される。混同行列は、予測結果と実際の結果を4つのカテゴリーに分類する。\textbf{TP（True Positive、真陽性）}は、バグありと予測し、実際にバグがあったケース、\textbf{TN（True Negative、真陰性）}は、バグなしと予測し、実際にバグがなかったケース、\textbf{FP（False Positive、偽陽性）}は、バグありと予測したが、実際にはバグがなかったケース、\textbf{FN（False Negative、偽陰性）}は、バグなしと予測したが、実際にはバグがあったケースである。

\textbf{適合率（Precision）}は、バグありと予測したもののうち、実際にバグがあった割合を示す。$Precision = \frac{TP}{TP + FP}$として計算される。適合率が高いほど、誤検出（偽陽性）が少ないことを意味する。\textbf{再現率（Recall）}は、実際にバグがあったもののうち、バグありと予測できた割合を示す。$Recall = \frac{TP}{TP + FN}$として計算される。再現率が高いほど、見逃し（偽陰性）が少ないことを意味する。

\textbf{F1スコア（F1-score）}は、適合率と再現率の調和平均であり、$F1 = 2 \times \frac{Precision \times Recall}{Precision + Recall}$として計算される。F1スコアは、適合率と再現率のバランスを評価する指標であり、両者が共に高い値を取るときに高くなる。本研究では、F1スコアを主要な評価指標として使用する。

ソフトウェアの変更履歴では、「バグが含まれるケース」が「正常なケース」に比べて圧倒的に少ないという、データの極端な偏り（クラス不均衡問題）がある。クラス不均衡が問題となる理由は、機械学習モデルが多数クラス（バグなし）に偏った予測を行い、少数クラス（バグあり）の検出精度が著しく低下するためである。この問題に対処するため、\textbf{オーバーサンプリング}（少数クラスのデータを人工的に増やす手法。例: SMOTE）や\textbf{アンダーサンプリング}（多数クラスのデータを削減する手法）といった手法が用いられる。本研究では、ランダムアンダーサンプリングを用いる。この手法を選択した理由は、オーバーサンプリングによる人工データの生成は過学習のリスクを高める可能性があるのに対し、アンダーサンプリングは実データのみを使用するため、モデルの汎化性能が安定しやすいためである。具体的には、バグありクラスとバグなしクラスから同数のデータを取得する。