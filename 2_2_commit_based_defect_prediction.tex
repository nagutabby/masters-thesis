コミット単位での欠陥予測は、バージョン管理システム（VCS: Version Control System）に記録された変更履歴を活用し、コードの変化と欠陥の関係を分析する手法である。VCSには、各コミットに対して、変更されたファイル、追加・削除された行、コミットメッセージ、作成者、作成日時などの情報が記録される。これらの情報を活用することで、開発者がコミットした直後に、その変更が欠陥を誘発するリスクを予測することが可能になる。この分野では、どのコミットが欠陥を混入させたかを特定するための手法と、コミット時点でのコードの特性を捉えるためのデータセット構築が重要な課題となっている。

Ferencら\cite{ferenc2020}は、GitHubからバグ情報を自動的に収集し、コミットごと、ソフトウェアの構成要素（メソッド、クラス）ごとのメトリクスを含む「BugHunter Dataset」を構築した。このデータセットの特徴は、従来の研究が特定のリリースバージョンにおける全てのソースコード要素の特性を収集していたのに対し、バグ混入コミットとバグ修正コミットという、バグの存在を特定できる最も狭い期間において、同じソースコード要素のバグあり状態と修正済み状態の両方を捉えることである。

データセット構築において、Ferencらは15のJavaプロジェクトを対象とし、欠陥が混入したコミットを特定するためにSZZアルゴリズムを用いた。この手法により、欠陥混入時と修正時のコードメトリクスを比較することが可能になる。

データセット構築の過程で、同じメトリクス値を持ちながら異なる数のバグが割り当てられているエントリーが存在するという問題に直面した。これは機械学習による欠陥予測の精度に悪影響を与える冗長性を生み出すため、Removal法、Subtract法、Single法、GCF法という4つのフィルタリング手法を比較検証した。その結果、より大きなエントリー数を持つクラスのエントリーを保持するRemoval法が最も高いF1スコアを達成した。また、クラス不均衡問題に対処するため、ランダムアンダーサンプリングを用いて、バグありクラスとバグなしクラスから同数のデータを取得した。

構築されたデータセットを用いた欠陥予測実験では、ナイーブベイズ、ロジスティック回帰、C4.5、ランダムフォレストなど11種類の機械学習アルゴリズムを比較評価した。ファイル、クラス、メソッドという3つのレベルで予測を実施した結果、メソッドレベルではランダムフォレストが最も高い性能を示し、平均F1スコアは約0.63であった。クラスレベルでは単純ロジスティック回帰が最も高く、平均F1スコアは約0.57、ファイルレベルではランダムツリーが最も高く、平均F1スコアは0.55であった。これらの結果は、より細かい粒度（メソッドレベル）での予測が、より高い精度を達成できることを示している。

一方、Hanらは、コードレビューを通じた欠陥検出の実態を調査した。OpenStackプロジェクトのNovaとNeutronを対象に、19,146件のレビューコメントを手動で分析し、将来の不具合を招く恐れのある不適切な構造がどの程度特定されるかを調査した。こうした不適切な構造とは、Martin Fowler が提唱した概念であり、コード内の潜在的な問題を示す特徴的なパターン（例: 肥大化したメソッド、重複コード、過度に複雑なクラス構造など）を指す。これらは必ずしも欠陥ではないが、保守性を低下させ、将来的に欠陥を誘発しやすくする要因となる。その結果、コードレビューでこうした不適切な構造が特定されることは一般的ではないことが明らかになった。約1,200件のレビューのうち、不適切な構造が明示的に指摘されたのは限られた数であった。さらに、レビューの大部分（70\%）では、特定された不適切な構造について説明が提供されておらず、レビュアーは単に問題を指摘するだけで、その理由を詳しく説明していなかった。

これらの研究から、コミットベースの欠陥予測における重要な課題が明らかになる。第一に、Ferencらの研究では各コミットの特性値を用いた予測が行われているが、コミット間の変化は対象外である。すなわち、あるコミット時点でのコードメトリクスは測定されているが、直前のコミットからどのように変化したかという時系列的な情報は活用されていない。第二に、Hanらの研究が示すように、コードレビューでは70\%のケースで欠陥の原因が明示されないため、レビューテキストのみから欠陥を予測することには限界がある。これらの課題は、コミット間の変化を考慮し、特性値同士の関連性を分析する新たなアプローチの必要性を示唆している。