3.4節で議論した手法に基づいて、レビュー労力を計算する。本節では、実装の詳細とデータセットへの適用について述べる。

\paragraph{レビュー労力の計算}
各コミット$i$のレビュー労力を算出するため、以下の手順を実行する。

まず、コミットの基本情報として、追加されたコード行数$LA_i$、削除されたコード行数$LD_i$、および変更されたファイル数$N_i$を取得する。レビュー労力の基本単位となるコードの全ての変更行数$C_i$は、これらを用いて$C_i = LA_i + LD_i$として算出される。

次に、変更の広がり$H_i$を、以下の情報理論のエントロピーを用いて計算する。

$$H_i = -\sum_{k=1}^{n_i} p_k \log_2 p_k$$

ここで、$n_i$はコミット$i$で変更されたファイル数であり、$p_k$は全変更行数に対する各ファイル$k$の変更行数の割合を表す。この$H_i$を$\log_2 n_i$で割ることで正規化した値を$\bar{H}_i$とし、これを変更の複雑度の重みとして用いる。

最終的なレビュー労力は、変更行数$C_i$に変更の複雑度を反映させた値を対数変換することで算出する。本研究では、エントロピーの計算（ビット単位の評価）と理論的な一貫性を持たせるため、底に2を用いた二進対数（$\log_2$）を採用する。

$$W_i = \log_2(C_i \times N_i^{\bar{H}_i} + 1)$$

この対数変換により、数千行を超えるような巨大なコミットの影響を緩和しつつ、中小規模のコミット間の相対的な労力の相違を適切に評価することができるようになる。

\paragraph{レビュー総労力の設定}
3.4節で定義した方法に従い、レビューに使える総労力$C_{total}$を設定する。全コミットをレビュー労力の昇順にソートし、上位80\%のコミットの労力の和を$C_{total}$とする。

\paragraph{密度の計算}
3.4節で定義した貪欲法による優先度付けを行うため、以下の式により密度$D_i$を計算する。

$$D_i = \frac{\hat{y}_i}{W_i}$$

ここで、$\hat{y}_i$はモデルが予測したコミット$i$の欠陥混入確率であり、$W_i$は前述の手順で算出した補正済みレビュー労力である。この密度$D_i$は、単位労力あたりの欠陥発見期待値を表し、レビュー対象コミットの優先順位付けに用いられる。

\paragraph{データセットへの適用}
BugHunterデータセットに含まれる各コミットについて、上記の手順に従ってレビュー労力と密度$D_i$を算出する。

\paragraph{統計的仮説検定}
提案手法の有効性を統計的に検証するため、以下の2つの検定を用いる。

\textbf{McNemar検定}: 二値分類の予測性能（F1スコア）について、提案手法とベースライン手法の間に統計的に有意な差があるかを検証する。McNemar検定は、対応のある2つの分類器の性能を比較する際に広く用いられ、各サンプルに対する2つのモデルの予測結果の不一致度を分析する。

\textbf{Wilcoxonの符号順位検定}: レビュー労力20\%と40\%の時点における欠陥発見率について、提案手法がベースライン手法より統計的に有意に優れているかを検証する。5つのプロジェクトを独立したサンプルとして扱い、各プロジェクトにおけるそれぞれの手法の欠陥発見率のペアを比較する。サンプルサイズが5と小さく、データの正規性が保証されないため、ノンパラメトリック検定であるWilcoxonの符号順位検定が適切である。本研究の目的は「提案手法がベースライン手法より優れている」ことの検証であるため、片側検定を採用する。

すべての統計的仮説検定において、有意水準は0.05とする。