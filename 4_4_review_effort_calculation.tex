3.4節で定義したナップサック問題アプローチに基づき、レビュー労力の計算を実装する。本節では、実装の詳細とデータセットへの適用について述べる。

\paragraph{実装の詳細}
各コミット $i$ のレビュー労力 $W_i$ を計算するため、以下の手順を実行する。

まず、コミットの基本情報を取得する。
\begin{itemize}
    \item 追加されたコード行数 $LA_i$
    \item 削除されたコード行数 $LD_i$
    \item 変更されたファイル数 $N_i$
    \item 各ファイル $k$ の変更行数
\end{itemize}

次に、3.4節で定義した計算式を順次適用する。

コードの変更行数 $C_i$ を計算する。
\[
C_i = LA_i + LD_i
\]

各ファイルが変更全体に占める割合 $p_k$ を計算する。
\[
p_k = \frac{\text{file}_k \text{の変更行数}}{\text{全変更行数}}
\]

変更の広がり $H_i$ を計算する。
\[
H_i = -\sum_{k=1}^{n_i} p_k \log_2 p_k
\]

変更の広がりを正規化する。
\[
H_i^{\text{norm}} = \frac{H_i}{\log_2 n_i}
\]

ベース労力 $E_{\text{raw}, i}$ を計算する。
\[
E_{\text{raw}, i} = C_i \times N_i^{H_i^{\text{norm}}}
\]

対数変換により補正済み労力 $W_i$ を計算する。
\[
W_i = E_{\text{adj}, i} = \ln(E_{\text{raw}, i} + 1)
\]

\paragraph{レビュー総労力の設定}
3.4節で定義した方法に従い、レビューに使える総労力 $C_{total}$ を設定する。全コミットをレビュー労力 $W_i$ の昇順にソートし、上位80\%のコミットの労力の和を $C_{total}$ とする。

\paragraph{密度の計算}
3.4節で定義した密度 $D_i$ を計算する。

\[
D_i = \frac{V_i}{W_i} = \frac{\hat{y}_i}{E_{\text{adj}, i}}
\]

ここで、$\hat{y}_i$ はモデルが予測したコミット $i$ の欠陥混入確率、$E_{\text{adj}, i}$ はコミット $i$ の補正済みレビュー労力である。密度は貪欲法におけるレビュー対象の優先順位付けに用いられる。

\paragraph{データセットへの適用}
BugHunterデータセットに含まれる各コミットについて、上記の手順に従ってレビュー労力 $W_i$ と密度 $D_i$ を算出する。これらの値は、貪欲法によるレビュー対象選択の入力として使用される。

\paragraph{統計的仮説検定}
まず、二値分類の予測性能（F1スコア）について、提案手法とベースライン手法の間に統計的に有意な差があるかを検証するため、マクネマー検定を用いる。マクネマー検定は、対応のある2つの分類器の性能を比較する際に広く用いられる手法であり、各サンプルに対する2つのモデルの予測結果の一致・不一致パターンを分析する。

次に、レビュー労力に対する欠陥発見率について、提案手法がベースライン手法より統計的に有意に優れているかを検証するため、ウィルコクソンの符号順位検定を用いる。本研究では、レビュー労力20\%と40\%の時点における欠陥発見率を評価対象とする。ウィルコクソンの符号順位検定は、対応のある2標本の比較に用いられるノンパラメトリック検定である。本研究では、5つのプロジェクトを独立したサンプルとして扱い、各プロジェクトにおけるベースライン手法と提案手法の欠陥発見率のペアを比較する。この検定により、複数のプロジェクトにわたって提案手法が一貫してベースライン手法を上回るかを統計的に検証できる。

サンプルサイズが5と小さく、データの正規性が保証されないため、正規性を仮定しないノンパラメトリック検定であるウィルコクソンの符号順位検定が適切である。また、本研究の目的は「提案手法がベースライン手法より優れている」ことの検証であるため、片側検定を採用する。

すべての統計的検定において、有意水準は0.05とする。