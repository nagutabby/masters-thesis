3.4節で定義したナップサック問題アプローチに基づき、レビュー労力の計算を実装する。本節では、実装の詳細とデータセットへの適用について述べる。

\paragraph{レビュー労力の計算}
各コミット $i$ のレビュー労力 $W_i$ を計算するため、以下の手順を実行する。

まず、コミットの基本情報を取得する。
\begin{itemize}
    \item 追加されたコード行数 $LA_i$
    \item 削除されたコード行数 $LD_i$
    \item 変更されたファイル数 $N_i$
\end{itemize}

次に、3.4節で定義した計算式を順次適用する。

レビュー労力の基本単位として、コードの変更行数 $C_i$ を計算する。
\[
C_i = LA_i + LD_i
\]

変更の広がりを定量化するため、各ファイルの変更が変更全体に占める割合 $p_k$ を計算する。
\[
p_k = \frac{\text{file}_k \text{の変更行数}}{\text{全変更行数}}
\]

情報理論のエントロピーを用いて、変更が複数のファイルに分散している度合いを表す変更の広がり $H_i$ を計算する。
\[
H_i = -\sum_{k=1}^{n_i} p_k \log_2 p_k
\]

ファイル数の違いによる影響を排除するため、変更の広がりを正規化する。
\[
H_i^{\text{norm}} = \frac{H_i}{\log_2 n_i}
\]

変更行数と変更の広がりを組み合わせて、ベース労力 $E_{\text{raw}, i}$ を計算する。変更の広がりが大きいほど、レビュー労力が増加する。
\[
E_{\text{raw}, i} = C_i \times N_i^{H_i^{\text{norm}}}
\]

極端に大きいレビュー労力を持つコミットの影響を抑制するため、対数変換により補正済み労力 $W_i$ を計算する。
\[
W_i = E_{\text{adj}, i} = \ln(E_{\text{raw}, i} + 1)
\]

\paragraph{レビュー総労力の設定}
3.4節で定義した方法に従い、レビューに使える総労力 $C_{total}$ を設定する。全コミットをレビュー労力 $W_i$ の昇順にソートし、上位80\%のコミットの労力の和を $C_{total}$ とする。

\paragraph{密度の計算}
3.4節で定義した密度 $D_i$ を計算する。

\[
D_i = \frac{V_i}{W_i} = \frac{\hat{y}_i}{E_{\text{adj}, i}}
\]

ここで、$\hat{y}_i$ はモデルが予測したコミット $i$ の欠陥混入確率、$E_{\text{adj}, i}$ はコミット $i$ の補正済みレビュー労力である。密度は貪欲法におけるレビュー対象の優先順位付けに用いられる。

\paragraph{データセットへの適用}
BugHunterデータセットに含まれる各コミットについて、上記の手順に従ってレビュー労力 $W_i$ と密度 $D_i$ を算出する。これらの値は、貪欲法によるレビュー対象選択の入力として使用される。

\paragraph{統計的仮説検定}
提案手法の有効性を統計的に検証するため、以下の2つの検定を用いる。

\textbf{マクネマー検定}: 二値分類の予測性能（F1スコア）について、提案手法とベースライン手法の間に統計的に有意な差があるかを検証する。マクネマー検定は、対応のある2つの分類器の性能を比較する際に広く用いられ、各サンプルに対する2つのモデルの予測結果の不一致度を分析する。

\textbf{ウィルコクソンの符号順位検定}: レビュー労力20\%と40\%の時点における欠陥発見率について、提案手法がベースライン手法より統計的に有意に優れているかを検証する。5つのプロジェクトを独立したサンプルとして扱い、各プロジェクトにおける両手法の欠陥発見率のペアを比較する。サンプルサイズが5と小さく、データの正規性が保証されないため、ノンパラメトリック検定であるウィルコクソンの符号順位検定が適切である。本研究の目的は「提案手法がベースライン手法より優れている」ことの検証であるため、片側検定を採用する。

すべての統計的仮説検定において、有意水準は0.05とする。