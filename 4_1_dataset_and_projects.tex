\paragraph{データセットの選定}
本研究の目的である、コミット間の不規則な変化を捉える欠陥予測モデルを構築するためには、単なるコードの状態だけでなく、「いつ欠陥が混入し、どのコミットで修正されたか」という対応関係を含むデータセットが必要である。

しかし、欠陥予測の研究で古くから用いられてきたNASA MDP（Metrics Data Program）やPROMISEデータセットは、プロジェクトの特定の時点における構造的メトリクスのみを提供しており、欠陥混入のタイミングという時系列情報が欠落している。また、近年広く利用されているDefects4J\cite{just2014}は、欠陥修正の直前・直後の状態に特化したデータセットであり、欠陥が「どの過去のコミットで」混入したかを遡って分析する用途には適さない。

そこで本研究では、以下の3つの要件を満たすBugHunterデータセット\cite{ferenc2020}を採用する。

\begin{enumerate}
    \item \textbf{欠陥の混入から修正までの流れを捉えられる}: BugHunterデータセットはSZZアルゴリズムを用いて欠陥混入コミットと欠陥修正コミットをペアで特定しており、欠陥の発生から収束までの情報を直接抽出できる。
    \item \textbf{分析対象の構成要素が揃っている}: 本研究が対象とするメソッド単位のメトリクスをあらかじめ保持しており、前処理のコストを抑えつつ詳細な分析が可能である。
    \item \textbf{比較的新しい開発環境に基づいている}: GitHubでホストされている実際のJavaプロジェクトから構築されており、CI/CDや頻繁なコミットが行われる現代の開発プロセスを反映している。
\end{enumerate}

また、BugHunterデータセットは、その公開以降、多くの欠陥予測研究で活用されている。Modanlouらは、BugHunterデータセットの全15プロジェクトをメソッドレベルで使用し、ディープニューラルネットワークを提案することで、平均F1スコア84.08\%を達成した\cite{modanlou2024}。Jászは、メソッドレベルでの隠れ依存関係メトリクスの有効性を検証し、従来のソフトウェアメトリクスと比較してF1スコアが11\%改善されることを示した\cite{jasz2024}。これらの先行研究は、BugHunterデータセットがメソッドレベルでの欠陥予測研究において有用であることを示している。

\paragraph{対象プロジェクトの選定}
BugHunterデータセットに含まれる15のプロジェクトの中から、統計的検定力を確保するため、データセットのレコード数が多いプロジェクトを優先的に選定する。

データセットの構築にはSZZアルゴリズム\cite{sliwerski2005}が用いられているため、解決済みのバグレポートの数とデータセットのレコード数の大きさには相関関係がある。そのため、解決済みのバグレポート数を基準として、データセットの相対的な大きさを推測できる。この基準に基づき、解決済みのバグレポート数が多い上位5つのプロジェクトを対象として選定した。

選定するプロジェクトの数を5つとした理由は、統計的検定力の確保とデータの多様性の維持を両立するためである。プロジェクト数が極めて限定的である場合、プロジェクト間の特性の差異を十分に網羅できず、提案手法の汎化性能を客観的に評価することが困難になる。本研究では、選定数を5つとすることで、複数の異なるドメインを幅広くカバーしつつ、McNemar検定などの統計的仮説検定において十分なサンプルサイズを確保した。これにより、得られた結果の統計的な有意性を担保し、手法の有効性についてより信頼性の高い議論が可能となる。

\begin{table}[ht]
\centering
\caption{対象プロジェクトとバグレポート数}
\begin{tabular}{|l|l|r|}
\hline
プロジェクト & ドメイン & バグレポート数 \\
\hline
Elasticsearch\cite{elasticsearch} & 分散検索・分析エンジン & 4,287 \\
Hazelcast\cite{hazelcast} & 分散コンピューティング & 3,762 \\
Netty\cite{netty} & ネットワークフレームワーク & 2,207 \\
OrientDB\cite{orientdb} & マルチモデルDB & 1,272 \\
Neo4j\cite{neo4j} & グラフDB & 1,152 \\
\hline
\end{tabular}
\end{table}

Elasticsearchは、分散検索・分析エンジンであり、大規模なログデータやテキストデータの検索に広く使用されている。Hazelcastは、インメモリデータグリッドを提供する分散コンピューティングプラットフォームである。Nettyは、高性能な非同期イベント駆動型のネットワークアプリケーションフレームワークである。OrientDBは、マルチモデルデータベースであり、グラフデータベースとドキュメントデータベースの機能を併せ持つ。Neo4jは、グラフデータベースの代表的な実装の一つであり、ソーシャルネットワーク分析や推薦システムなど、関係性を重視するアプリケーションで広く使用されている。

これらは、いずれもJavaで記述されている活発なOSSプロジェクトである。ドメインは検索エンジン、分散システム、ネットワークフレームワーク、データベースと多岐にわたり、異なる開発特性を持つ。このような多様性により、提案手法が特定のプロジェクトに依存せず、広範なソフトウェアシステムに適用可能であることを検証できる。

\paragraph{正解ラベルと構成要素の違い}
本研究では、メソッド単位での欠陥予測を行う。この構成単位での分析を採用した理由は、欠陥の局所性と予測精度の観点から説明できる。多くの欠陥は特定のメソッド内のロジックエラーや境界条件の誤りに起因しており、メソッド単位での予測は、クラスやファイル単位での予測よりも欠陥の特徴を捉えやすい。さらに、メソッド単位での予測では個々のメソッドの複雑度や変更量といった詳細な特徴量を利用できるため、より正確な予測が可能となる。

メソッド単位での欠陥予測を行うため、各メソッドに含まれる欠陥の数を二値化して正解ラベルとする。具体的には、欠陥の数が0のメソッドを「欠陥を含まないデータ」、欠陥の数が1以上のメソッドを「欠陥を含むデータ」に分類する。この二値分類により、ランダムフォレストのような分類アルゴリズムを適用できる形式にデータを整形する。

\paragraph{データの前処理と使用レコード数}
データの前処理として、以下の処理を実施する。第一に、値が全て同じであるカラムを削除する。これらのカラムは予測に寄与しないため、モデルの複雑性を低減するために除外する。第二に、メソッドの識別子をベクトルに変換する。メソッド名やクラス名といった識別子をそのまま用いると、各識別子を独立したカテゴリーとして扱うことになり、未知の識別子に対する汎化性能が低下する。トークン分割により識別子を構成要素に分解することで、複数のメソッドが特定の共通要素を持つことを認識でき、構成要素の類似性を表す特徴量として活用できる。

交差検証時の評価指標の安定化を図るため、各プロジェクトのデータセットから抽出するレコード数の上限を5,000行とする。この設定の根拠は、統計的信頼性の確保である。

10分割交差検証においては、5,000行のレコードを各サブセット（約500行）に分配することで、不均衡データであっても少数クラスのサンプルを十分に確保できる。これにより、交差検証の各フェーズにおけるF1スコアの変動を抑制し、評価指標の安定性を高めることが可能となる。

データ抽出の際、利用可能なデータが5,000行以下の場合は全データを使用し、5,000行を超える場合は最初の5,000行を使用する。データセット内のレコードは、必ずしも時系列順に並んでいるわけではないが、同一メソッドの複数のバージョン（欠陥混入時と修正時）が含まれており、これらの情報を用いて変化量を計算することができる。
