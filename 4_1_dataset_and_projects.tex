\paragraph{データセットの選定}
本研究では、Ferencらが構築したBugHunterデータセット\cite{ferenc2020}を使用する。このデータセットは、GitHub\cite{github}でホストされている15のJavaプロジェクトから自動的に収集されたバグ情報と、各コミットにおけるソースコード要素(ファイル、クラス、メソッド)のメトリクスを含んでいる。

欠陥予測研究では、これまで複数のベンチマークデータセットが用いられてきた。初期の研究では、NASA MDP（Metrics Data Program）データセットやPROMISEデータセットが広く使用され、多くの予測モデルの評価基盤となった。しかし、NASA MDPデータセットは各プロジェクトの単一スナップショットに基づく静的メトリクスを、PROMISEデータセットは主に各プロジェクトのバージョンごとの静的メトリクスを提供するものであり、バグが「どのコミットで」混入したかという時系列情報が欠落している。近年では、Defects4J\cite{just2014}がソフトウェアテスト研究で広く用いられているが、これは「バグ修正の直前・直後($V_{bug}$と$V_{fix}$)」の状態を高度に隔離して提供するデータセットであり、やはりバグ混入時点の情報は含まれていない。

本研究においてBugHunterデータセットを採用した理由は以下の3点に集約される。第一に、バグのライフサイクル全体を捕捉できる点である。PROMISEやNASAデータセットが提供する静的なスナップショットや、Defects4Jが提供する修正前後の状態に対し、BugHunterはバグ混入コミットとバグ修正コミットをペアで特定しており、バグの発生から収束までの時系列を捉えている。これにより、本研究の核となる「同一メソッド内での時系列的な変化量（変更メトリクス）」の算出が可能となる。第二に、分析粒度の適合性である。PROMISEやNASAデータセットは主にモジュールやファイル単位、Defects4Jはファイルやクラス単位での管理が主であるのに対し、BugHunterはメソッドレベルでの豊富なコードメトリクスを最初から提供しており、本研究が目的とする「メソッド単位の欠陥予測」を前処理のコストを抑えつつ直接実施できる。第三に、現代的な開発環境への適応性である。BugHunterはGitHubでホストされる実際のOSSプロジェクトから構築されており、バージョン管理システムと統合された継続的な開発プロセスを反映している点で、PROMISEやNASAの歴史的データセットよりも現代の開発実態に即している。

\paragraph{対象プロジェクトの選定}
有意性検定で帰無仮説が棄却されない問題を回避するため、BugHunterデータセットに含まれる15のプロジェクトの中から、データセットのレコード数が多いプロジェクトを優先的に選定する。

データセットの構築にはSZZアルゴリズム\cite{sliwerski2005}が用いられているため、解決済みのバグレポートの数とデータセットのレコード数の大きさには相関関係がある。そのため、解決済みのバグレポート数を基準として、データセットの相対的な大きさを推測できる。この基準に基づき、解決済みのバグレポート数が多い上位5つのプロジェクトを対象として選定した。

5つという数を選定した根拠は、統計的検定力とデータ多様性のバランスである。3つ以下では、プロジェクト間の多様性が不足し、提案手法の汎化性能を十分に評価できない。一方、10つ以上では、各プロジェクトの詳細な分析が困難になり、計算コストも増大する。5つのプロジェクトは、異なるドメイン(検索エンジン、分散システム、ネットワークフレームワーク、データベース)をカバーしながら、マクネマー検定などの統計的検定を行うのに十分なデータ量を確保できる。

\begin{table}[ht]
\centering
\caption{各プロジェクトのバグレポート数}
\begin{tabular}{|l|r|}
\hline
プロジェクト & バグレポート数 \\
\hline
Elasticsearch\cite{elasticsearch} & 4,287 \\
Hazelcast\cite{hazelcast} & 3,762 \\
Netty\cite{netty} & 2,207 \\
OrientDB\cite{orientdb} & 1,272 \\
Neo4j\cite{neo4j} & 1,152 \\
\hline
\end{tabular}
\end{table}

Elasticsearchは、分散検索・分析エンジンであり、大規模なログデータやテキストデータの検索に広く使用されている。
Hazelcastは、インメモリデータグリッドを提供する分散コンピューティングプラットフォームである。
Nettyは、高性能な非同期イベント駆動型のネットワークアプリケーションフレームワークである。
OrientDBは、マルチモデルデータベースであり、グラフデータベースとドキュメントデータベースの機能を併せ持つ。
Neo4jは、グラフデータベースの代表的な実装の一つであり、ソーシャルネットワーク分析や推薦システムなど、関係性を重視するアプリケーションで広く使用されている。

これらは、いずれもJavaで記述されている活発なOSSプロジェクトである。ドメインは検索エンジン、分散システム、ネットワークフレームワーク、データベースと多岐にわたり、異なる開発特性を持つ。このような多様性により、提案手法が特定のプロジェクトに依存せず、広範なソフトウェアシステムに適用可能であることを検証できる。

\paragraph{正解ラベルの定義}
本研究では、メソッドレベルでの欠陥予測を行う。メソッドレベルを採用した理由は以下の通りである。第一に、レビュアーの実際の作業単位との対応である。コードレビューでは、レビュアーは個々のメソッドやクラスに注目して変更内容を確認する。ファイルレベルやコミットレベルでは粒度が粗すぎて、具体的なレビュー箇所の特定が困難である。第二に、バグの局所性である。多くのバグは特定のメソッド内のロジックエラーや境界条件の誤りに起因しており、メソッドレベルでの予測がバグの本質を捉えやすい。第三に、予測精度の向上である。メソッドレベルでは、個々のメソッドの複雑度や変更量といった詳細な特徴量を利用できるため、ファイルレベルよりも精緻な予測が可能となる。

メソッドレベルでの欠陥予測を行うため、各メソッドに含まれるバグの数を二値化して正解ラベルとする。具体的には、バグの数が0のメソッドを「バグなし」クラス、バグの数が1以上のメソッドを「バグあり」クラスに分類する。この二値分類により、ランダムフォレストのような分類アルゴリズムを適用できる形式にデータを整形する。

\paragraph{データの前処理}
第一に、値が全て同じであるカラムを削除する。これらのカラムは予測に寄与しないため、モデルの複雑性を低減するために除外する。

第二に、メソッドの識別子をベクトルに変換する。メソッド名やクラス名といった識別子は、そのままでは機械学習モデルに入力できないため、トークン分割などの手法を用いて数値ベクトルに変換する。

\paragraph{使用するレコード数の上限}
交差検証時の評価指標の安定化を図るため、各プロジェクトのデータセットから抽出するデータポイント数の上限を5,000件とする。この設定の根拠は以下の通りである。

第一に、統計的信頼性の確保である。当初は3,000件を上限としていたが、この設定では交差検証のフェーズごとにF1スコアが大きく変動し、最悪と最良のフェーズを比較すると0.1前後の誤差が生じていた。データポイント数を5,000件に増やすことで、各フォルドに含まれるバグありサンプルの数が増加し、この変動を抑制できた。10分割交差検証では各フォルドに約500件が含まれるため、不均衡データにおいても少数クラスのサンプルが十分に確保される。

第二に、計算コストとの兼ね合いである。ランダムフォレストの訓練には$O(n \log n)$の計算量が必要であり、データサイズが大きくなるほど計算時間が増大する。5,000件という設定は、1プロジェクトあたり数分程度での訓練を可能にし、複数回の実験を実行できる実用的な範囲である。また、使用するメモリ量も制限されるため、一般的な計算機環境での実行が可能となる。

ただし、この変動は完全には解消されておらず、データの特性に起因する課題として残っている。各プロジェクトのデータセットから、利用可能なデータが5,000件以下の場合は全データを使用し、5,000件を超える場合は最初の5,000件を使用する。データセット内のレコードは必ずしも時系列順に並んでいるわけではないが、同一メソッドの複数のバージョン(バグ混入時と修正時)が含まれており、これらの情報を用いて変化量を計算することが可能である。