\paragraph{データセットの選定}
本研究では、Ferencらが構築したBugHunterデータセット\cite{ferenc2020}を使用する。このデータセットは、GitHubでホストされている15のJavaプロジェクトから自動的に収集された欠陥情報と、各コミットにおけるソースコード要素（ファイル、クラス、メソッド）のメトリクスを含む。

欠陥予測研究では、これまで欠陥予測を実現するために様々なデータセットが用いられてきた。初期の研究では、NASA MDP（Metrics Data Program）データセットやPROMISEデータセットが広く使用され、多くの予測モデルの評価基盤となった。しかし、これらのデータセットは各プロジェクトの構造の特徴に基づくメトリクスを提供するものであり、欠陥が「どのコミットで」混入したかという時系列情報が欠落している。近年では、Defects4J\cite{just2014}がソフトウェアテスト研究で広く用いられているが、これは欠陥修正の直前・直後の状態を提供するデータセットであり、欠陥混入時点の情報は含まれていない。

本研究においてBugHunterデータセットを採用した理由は以下の3点である。第一に、欠陥のライフサイクル全体を捕捉できる点である。BugHunterは欠陥混入コミットと欠陥修正コミットをペアで特定しており、欠陥の発生から収束までの時系列を捉えている。これにより、本研究の核となる「同一メソッド内での時系列的な変化量（変更メトリクス）」の算出が可能となる。第二に、分析する構成要素の適合性である。BugHunterはメソッドレベルでの豊富なコードメトリクスを最初から提供しており、本研究が目的とする「メソッド単位の欠陥予測」を前処理のコストを抑えつつ直接実施できる。第三に、現代的な開発環境への適応性である。BugHunterはGitHubでホストされる実際のOSSプロジェクトから構築されており、バージョン管理システムと統合された継続的な開発プロセスを反映している点で、古いデータセットよりも現代の開発実態に即している。

また、BugHunterデータセットは、その公開以降、多くの欠陥予測研究で活用されている。Modanlouらは、BugHunterデータセットの全15プロジェクトをメソッドレベルで使用し、ディープニューラルネットワークを提案することで、平均F1スコア84.08\%を達成した\cite{modanlou2024}。Jászは、メソッドレベルでの隠れ依存関係メトリクスの有効性を検証し、従来のソフトウェアメトリクスと比較してF1スコアが11\%改善されることを示した\cite{jasz2024}。これらの先行研究は、BugHunterデータセットがメソッドレベルでの欠陥予測研究において有用であることを示している。

\paragraph{対象プロジェクトの選定}
BugHunterデータセットに含まれる15のプロジェクトの中から、統計的検定力を確保するため、データセットのレコード数が多いプロジェクトを優先的に選定する。

データセットの構築にはSZZアルゴリズム\cite{sliwerski2005}が用いられているため、解決済みのバグレポートの数とデータセットのレコード数の大きさには相関関係がある。そのため、解決済みのバグレポート数を基準として、データセットの相対的な大きさを推測できる。この基準に基づき、解決済みのバグレポート数が多い上位5つのプロジェクトを対象として選定した。

選定するプロジェクトの数を5つとした理由は、統計的検定力とデータの多様性のバランスを考慮したためである。プロジェクトの数が少なすぎると、プロジェクト間の多様性が不足し、提案手法の汎化性能を十分に評価できない。一方、プロジェクトの数が多すぎると、各プロジェクトの詳細な分析が困難になり、計算コストも増大する。選定するプロジェクトの数を5つとすることにより、異なるドメイン（検索エンジン、分散システム、ネットワークフレームワーク、データベース）をカバーしながら、マクネマー検定などの検定を行うのに十分なサンプルサイズを確保する。

\begin{table}[ht]
\centering
\caption{対象プロジェクトとバグレポート数}
\begin{tabular}{|l|l|r|}
\hline
プロジェクト & ドメイン & バグレポート数 \\
\hline
Elasticsearch\cite{elasticsearch} & 分散検索・分析エンジン & 4,287 \\
Hazelcast\cite{hazelcast} & 分散コンピューティング & 3,762 \\
Netty\cite{netty} & ネットワークフレームワーク & 2,207 \\
OrientDB\cite{orientdb} & マルチモデルDB & 1,272 \\
Neo4j\cite{neo4j} & グラフDB & 1,152 \\
\hline
\end{tabular}
\end{table}

Elasticsearchは、分散検索・分析エンジンであり、大規模なログデータやテキストデータの検索に広く使用されている。Hazelcastは、インメモリデータグリッドを提供する分散コンピューティングプラットフォームである。Nettyは、高性能な非同期イベント駆動型のネットワークアプリケーションフレームワークである。OrientDBは、マルチモデルデータベースであり、グラフデータベースとドキュメントデータベースの機能を併せ持つ。Neo4jは、グラフデータベースの代表的な実装の一つであり、ソーシャルネットワーク分析や推薦システムなど、関係性を重視するアプリケーションで広く使用されている。

これらは、いずれもJavaで記述されている活発なOSSプロジェクトである。ドメインは検索エンジン、分散システム、ネットワークフレームワーク、データベースと多岐にわたり、異なる開発特性を持つ。このような多様性により、提案手法が特定のプロジェクトに依存せず、広範なソフトウェアシステムに適用可能であることを検証できる。

\paragraph{正解ラベルと構成要素の違い}
本研究では、メソッド単位での欠陥予測を行う。この構成単位での分析を採用した理由は、欠陥の局所性と予測精度の観点から説明できる。多くの欠陥は特定のメソッド内のロジックエラーや境界条件の誤りに起因しており、メソッド単位での予測は、クラスやファイル単位での予測よりも欠陥の特徴を捉えやすい。さらに、メソッド単位での予測では個々のメソッドの複雑度や変更量といった詳細な特徴量を利用できるため、より正確な予測が可能となる。

メソッド単位での欠陥予測を行うため、各メソッドに含まれる欠陥の数を二値化して正解ラベルとする。具体的には、欠陥の数が0のメソッドを「欠陥を含まないデータ」、欠陥の数が1以上のメソッドを「欠陥を含むデータ」に分類する。この二値分類により、ランダムフォレストのような分類アルゴリズムを適用できる形式にデータを整形する。

\paragraph{データの前処理と使用レコード数}
データの前処理として、以下の処理を実施する。第一に、値が全て同じであるカラムを削除する。これらのカラムは予測に寄与しないため、モデルの複雑性を低減するために除外する。第二に、メソッドの識別子をベクトルに変換する。メソッド名やクラス名といった識別子をそのまま用いると、各識別子を独立したカテゴリーとして扱うことになり、未知の識別子に対する汎化性能が低下する。トークン分割により識別子を構成要素に分解することで、複数のメソッドが特定の共通要素を持つことを認識でき、構成要素の類似性を表す特徴量として活用できる。

交差検証時の評価指標の安定化を図るため、各プロジェクトのデータセットから抽出するレコード数の上限を5,000行とする。この設定の根拠は以下の通りである。

第一に、統計的信頼性の確保である。当初は3,000行を上限としていたが、この設定では交差検証のフェーズごとにF1スコアが大きく変動し、最悪と最良のフェーズを比較すると0.1前後の誤差が生じていた。レコード数を5,000行に増やすことで、各サブセットに含まれる欠陥を含むデータの数が増加し、この変動を抑制できた。10分割交差検証では各サブセットに約500行のレコードが含まれるため、不均衡データにおいても少数クラスのサンプルが十分に確保される。

第二に、計算コストとの兼ね合いである。ランダムフォレストの訓練には$O(n \log n)$の計算量が必要であり、データサイズが大きくなるほど計算時間が増大する。5,000行という設定は、1プロジェクトあたり数十秒から数分程度での訓練を可能にし、複数回の実験を実行できる実用的な範囲である。また、使用するメモリ量も制限されるため、一般的なハードウェアでの実行が可能となる。

各プロジェクトのデータセットから、利用可能なデータが5,000行以下の場合は全データを使用し、5,000行を超える場合は最初の5,000行を使用する。データセット内のレコードは必ずしも時系列順に並んでいるわけではないが、同一メソッドの複数のバージョン（欠陥混入時と修正時）が含まれており、これらの情報を用いて変化量を計算することができる。
