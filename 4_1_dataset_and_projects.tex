\paragraph{データセットの選定}
本研究の目的である、コミット間の不規則な変化を捉える欠陥予測モデルを構築するためには、単なるコードの状態だけでなく、「いつ欠陥が混入し、どのコミットで修正されたか」という対応関係を含むデータセットが必要である。

しかし、欠陥予測の研究で古くから用いられてきたNASA MDP（Metrics Data Program）やPROMISEデータセットは、プロジェクトの特定の時点における構造的メトリクスのみを提供しており、欠陥混入のタイミングという時系列情報が欠落している。また、近年広く利用されているDefects4J\cite{just2014}は、欠陥修正の直前・直後の状態に特化したデータセットであり、欠陥が「どの過去のコミットで」混入したかを遡って分析する用途には適さない。

そこで本研究では、以下の3つの要件を満たすBugHunterデータセット\cite{ferenc2020}を採用する。

\begin{enumerate}
    \item \textbf{欠陥の混入から修正までの流れを捉えられる}: BugHunterデータセットは、欠陥混入コミットと欠陥修正コミットをペアで特定しており、欠陥の発生から収束までの情報を直接抽出できる。
    \item \textbf{分析対象の構成要素が揃っている}: 本研究が対象とするメソッド単位のメトリクスをあらかじめ保持しており、前処理のコストを抑えながら詳細な分析を行える。
    \item \textbf{比較的新しい開発環境に基づいている}: GitHubでホストされている実際のJavaプロジェクトから構築されており、CI/CDや細かな変更が行われる現代の開発プロセスを反映している。
\end{enumerate}

また、BugHunterデータセットは、その公開以降、多くの欠陥予測研究で活用されている。Modanlouらは、BugHunterデータセットの全15プロジェクトをメソッドレベルで使用し、ディープニューラルネットワークを提案することで、平均F1スコア84.08\%を達成した\cite{modanlou2024}。Jászは、メソッドレベルでの隠れ依存関係メトリクスの有効性を検証し、従来のソフトウェアメトリクスと比較してF1スコアが11\%改善されることを示した\cite{jasz2024}。これらの先行研究は、BugHunterデータセットがメソッドレベルでの欠陥予測研究において有用であることを示している。

\paragraph{対象プロジェクトの選定}
BugHunterデータセットに含まれる15のプロジェクトの中から、統計的検定力を確保するため、データセットのレコード数が多いプロジェクトを優先的に選定する。

データセットの構築にはSZZアルゴリズム\cite{sliwerski2005}が用いられているため、解決済みのバグレポートの数とデータセットのレコード数の大きさには相関関係がある。そのため、解決済みのバグレポートの数を基準として、データセットの相対的な大きさを推測できる。この基準に基づき、解決済みのバグレポートの数が多い上位5つのプロジェクトを対象として選定した。

選定するプロジェクトの数を5つとした理由は、統計的検定力の確保とデータの多様性の維持を両立するためである。プロジェクト数が極めて限定的である場合、プロジェクト間の特性の差異を十分に網羅できず、提案手法の汎化性能を客観的に評価することが困難になる。本研究では、選定数を5つとすることで、複数の異なるドメインをカバーしつつ、McNemar検定などの統計的仮説検定において十分なサンプルサイズを確保する。これにより、得られた結果の統計的な有意性が担保され、手法の有効性について、より信頼性の高い議論を行えるようになる。

\begin{table}[ht]
\centering
\caption{対象プロジェクトとバグレポート数}
\begin{tabular}{|l|l|r|}
\hline
プロジェクト & ドメイン & バグレポート数 \\
\hline
Elasticsearch\cite{elasticsearch} & 分散検索・分析エンジン & 4,287 \\
Hazelcast\cite{hazelcast} & 分散コンピューティング & 3,762 \\
Netty\cite{netty} & ネットワークフレームワーク & 2,207 \\
OrientDB\cite{orientdb} & マルチモデルDB & 1,272 \\
Neo4j\cite{neo4j} & グラフDB & 1,152 \\
\hline
\end{tabular}
\end{table}

Elasticsearchは、分散検索・分析エンジンであり、大規模なログデータやテキストデータの検索に広く使用されている。Hazelcastは、インメモリデータグリッドを提供する分散コンピューティングプラットフォームである。Nettyは、高性能な非同期イベント駆動型のネットワークアプリケーションフレームワークである。OrientDBは、マルチモデルデータベースであり、グラフデータベースとドキュメントデータベースの機能を併せ持つ。Neo4jは、グラフデータベースの代表的な実装の一つであり、ソーシャルネットワーク分析や推薦システムなど、関係性を重視するアプリケーションで広く使用されている。

これらは、いずれもJavaで記述されている活発なOSSプロジェクトである。ドメインは検索エンジン、分散システム、ネットワークフレームワーク、データベースと多岐にわたり、それぞれのプロジェクトが異なる開発特性を持つため、提案手法が様々なプロジェクトにおいて有効であることを検証できる。

\paragraph{正解ラベルと構成要素の相違}
本研究では、メソッド単位での欠陥予測を行う。なぜなら、メソッド単位の予測では構成要素の大きさが比較的小さく、欠陥の特徴を捉えやすいためである。実際に、BugHunterデータセットを用いた先行研究において、メソッド単位のデータセットを用いた場合に最も予測精度が高くなることが示されている。

メソッド単位での欠陥予測を行うため、各メソッドに含まれる欠陥の数を二値化して正解ラベルとする。具体的には、欠陥の数が0のメソッドを「欠陥を含まないデータ」、欠陥の数が1以上のメソッドを「欠陥を含むデータ」に分類する。この二値分類により、ランダムフォレストのような分類アルゴリズムを適用できる形式にデータを整形する。

\paragraph{データの前処理と使用レコード数}
データの前処理として、以下の処理を実施する。まず、値が全て同じであるカラムを削除する。なぜなら、これらのカラムは予測に寄与しないためである。次に、メソッドの識別子をベクトルに変換する。なぜなら、メソッド名やクラス名といった識別子をそのまま用いると、各識別子を独立したカテゴリーとして扱うことになり、未知の識別子に対する汎化性能が低下するためである。メソッドの識別子をいくつかの要素に分解することで、それらの識別子を要素の類似性を表す特徴量に変換し、複数のメソッドが特定の共通要素を持つことを機械学習モデルに認識させることができる。

交差検証時の評価指標の安定化を図るため、各プロジェクトのデータセットから抽出するレコード数の上限を5,000行とする。10分割交差検証においては、5,000行のレコードを各サブセット（約500行）に分配することで、不均衡データであっても少数クラスのサンプルを十分に確保できる。これにより、交差検証の各フェーズにおけるF1スコアの変動を抑制し、評価指標の安定性を高めることができる。

データ抽出の際、利用可能なデータが5,000行以下の場合は全てのデータを使用し、5,000行を超える場合は最初の5,000行を使用する。データセット内のレコードは、必ずしも時系列順に並んでいるわけではないが、同一メソッドの複数のバージョン（欠陥混入時と修正時）が含まれており、これらの情報を用いて変化量を計算することができる。